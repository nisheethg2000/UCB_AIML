{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Customer Service Chatbot with DialogGPT for Conversational Intents",
        "",
        "This Jupyter Notebook replaces BlenderBot with Microsoft’s DialogGPT in `evaluate_chatbot_data_blenderbot_twitter_trained.ipynb` for a trucking company chatbot due to Rasa compatibility issues. It inspects `trucking_chatbot_test_dataset.csv` or `tweets.csv`, trains a DistilBERT model for intent classification, and fine-tunes DialogGPT on Twitter data for conversational intents (greeting, farewell, small_talk, compliment, weather_query). DistilBERT handles trucking-specific intents (delivery_status, billing_issue, account_update, service_inquiry, fuel_card_query, general_query). Includes interactive UI with ipywidgets.",
        "",
        "## Objectives",
        "- Inspect Twitter dataset for intents and entities (e.g., location, company).",
        "- Train DistilBERT for intent classification using Twitter dataset.",
        "- Fine-tune DialogGPT on conversational Twitter data.",
        "- Evaluate DistilBERT with accuracy, F1-score, confusion matrix, and dialogue success rate.",
        "- Implement hybrid dialogue management with DialogGPT and DistilBERT.",
        "- Provide interactive UI for customer interaction.",
        "",
        "## Requirements",
        "- Python 3.8+ (recommended: 3.8 or 3.9)",
        "- Install: `pip install pandas==2.0.3 numpy==1.24.4 scikit-learn==1.3.2 transformers==4.35.2 datasets==2.15.0 torch==2.1.0 seaborn==0.13.0 matplotlib==3.8.2 ipywidgets==8.1.1`",
        "- Place `trucking_chatbot_test_dataset.csv` or `tweets.csv` in the directory.",
        "- Enable widgets: `jupyter nbextension enable --py widgetsnbextension`",
        "",
        "## Notes",
        "- Uses Twitter dataset: https://www.kaggle.com/thoughtvector/customer-support-on-twitter",
        "- Reflects tariffs/Moody’s downgrade in billing/fuel inquiries.",
        "- Responses are professional, with dynamic DialogGPT conversation.",
        "- Date/time: May 29, 2025, 01:34 AM EDT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from datetime import datetime\n",
        "import os\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Inspect and Preprocess Dataset",
        "",
        "Load Twitter dataset, add conversational examples, label intents/entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inspect_dataset(file_path='trucking_chatbot_test_dataset.csv'):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print('Dataset not found. Using Twitter dataset.')\n",
        "        try:\n",
        "            df = pd.read_csv('tweets.csv')\n",
        "        except FileNotFoundError:\n",
        "            print('Download from: https://www.kaggle.com/thoughtvector/customer-support-on-twitter')\n",
        "            # Simulated data with conversational intents\n",
        "            data = {\n",
        "                'text': [\n",
        "                    'Where is my shipment from Speedway?',\n",
        "                    'Why is my Comdata bill so high?',\n",
        "                    'Need to update my address for IFTA',\n",
        "                    'What are your hauling rates?',\n",
        "                    'Help with my account',\n",
        "                    'Hello',\n",
        "                    'How are you',\n",
        "                    'How can I help you',\n",
        "                    'Track my cargo',\n",
        "                    'Overcharged on Comdata invoice',\n",
        "                    'Hi there',\n",
        "                    'Change my contact info',\n",
        "                    'Tell me about Comdata services',\n",
        "                    'Lost my shipment',\n",
        "                    'Good morning',\n",
        "                    'Thanks for your help',\n",
        "                    'Bye',\n",
        "                    'What’s new?',\n",
        "                    'How’s it going?',\n",
        "                    'How’s your day going?',\n",
        "                    'Any big plans?',\n",
        "                    'How’s the trucking life?',\n",
        "                    'You’re awesome!',\n",
        "                    'Great job!',\n",
        "                    'How’s the weather there?',\n",
        "                    'Is it raining?'\n",
        "                ],\n",
        "                'intent': [\n",
        "                    'delivery_status',\n",
        "                    'billing_issue',\n",
        "                    'account_update',\n",
        "                    'service_inquiry',\n",
        "                    'general_query',\n",
        "                    'greeting',\n",
        "                    'greeting',\n",
        "                    'greeting',\n",
        "                    'delivery_status',\n",
        "                    'billing_issue',\n",
        "                    'greeting',\n",
        "                    'account_update',\n",
        "                    'fuel_card_query',\n",
        "                    'general_query',\n",
        "                    'greeting',\n",
        "                    'farewell',\n",
        "                    'farewell',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'compliment',\n",
        "                    'compliment',\n",
        "                    'weather_query',\n",
        "                    'weather_query'\n",
        "                ]\n",
        "            }\n",
        "            df = pd.DataFrame(data)\n",
        "\n",
        "    # Enhanced keywords\n",
        "    keywords = ['delivery', 'shipment', 'cargo', 'bill', 'invoice', 'payment', 'account', 'service', 'hauling', 'truck',\n",
        "                'comdata', 'ifta', 'speedway', 'fuel', 'tax', 'station', 'hello', 'hi', 'how', 'good', 'bye', 'thanks',\n",
        "                'new', 'day', 'plans', 'awesome', 'great', 'weather', 'rain']\n",
        "    if 'text' in df.columns:\n",
        "        df = df[df['text'].str.contains('|'.join(keywords), case=False, na=False)]\n",
        "        df = df.sample(n=min(10000, len(df)), random_state=42)\n",
        "\n",
        "    # Label intents if not provided\n",
        "    if 'intent' not in df.columns:\n",
        "        def label_intent(text):\n",
        "            text = text.lower()\n",
        "            if any(word in text for word in ['hello', 'hi', 'how are you', 'how can i help', 'good morning', 'good afternoon']):\n",
        "                return 'greeting'\n",
        "            elif any(word in text for word in ['goodbye', 'bye', 'thanks', 'thank you']):\n",
        "                return 'farewell'\n",
        "            elif any(word in text for word in ['what’s new', 'how’s it going', 'how’s your day', 'any big plans', 'trucking life']):\n",
        "                return 'small_talk'\n",
        "            elif any(word in text for word in ['awesome', 'great job', 'you rock']):\n",
        "                return 'compliment'\n",
        "            elif any(word in text for word in ['weather', 'rain', 'sunny']):\n",
        "                return 'weather_query'\n",
        "            elif any(word in text for word in ['delivery', 'shipment', 'track', 'cargo']):\n",
        "                return 'delivery_status'\n",
        "            elif any(word in text for word in ['bill', 'invoice', 'payment', 'charge']):\n",
        "                return 'billing_issue'\n",
        "            elif any(word in text for word in ['update', 'change', 'address', 'contact']):\n",
        "                return 'account_update'\n",
        "            elif any(word in text for word in ['service', 'rate', 'hauling']):\n",
        "                return 'service_inquiry'\n",
        "            elif any(word in text for word in ['comdata', 'ifta', 'fuel', 'tax']):\n",
        "                return 'fuel_card_query'\n",
        "            else:\n",
        "                return 'general_query'\n",
        "        df['intent'] = df['text'].apply(label_intent)\n",
        "\n",
        "    # Entity extraction\n",
        "    def extract_entities(text):\n",
        "        entities = []\n",
        "        text = text.lower()\n",
        "        if 'speedway' in text:\n",
        "            entities.append({'entity': 'location', 'value': 'Speedway'})\n",
        "        if 'comdata' in text:\n",
        "            entities.append({'entity': 'company', 'value': 'Comdata'})\n",
        "        if 'ifta' in text:\n",
        "            entities.append({'entity': 'regulation', 'value': 'IFTA'})\n",
        "        return entities\n",
        "\n",
        "    df['entities'] = df['text'].apply(extract_entities)\n",
        "\n",
        "    print('Dataset Shape:', df.shape)\n",
        "    print('Columns:', df.columns.tolist())\n",
        "    print('Sample Rows:\\n', df.head())\n",
        "    print('Missing Values:\\n', df.isnull().sum())\n",
        "    print('Intent Distribution:\\n', df['intent'].value_counts())\n",
        "    print('Entity Samples:\\n', df[df['entities'].apply(len) > 0][['text', 'entities']].head())\n",
        "    return df\n",
        "\n",
        "# Inspect\n",
        "df = inspect_dataset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Prepare DialogGPT Training Data",
        "",
        "Prepare conversational Twitter data for DialogGPT fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dialoggpt_training_data(df):\n",
        "    conversational_intents = ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "    df_conversational = df[df['intent'].isin(conversational_intents)][['text', 'intent']]\n",
        "\n",
        "    # Create response mapping\n",
        "    response_map = {\n",
        "        'greeting': [\n",
        "            'Hello! How can I assist you with your trucking needs today?',\n",
        "            'Hi there! Ready to help with your shipments or account!',\n",
        "            'Good to hear from you! What’s up?'\n",
        "        ],\n",
        "        'farewell': [\n",
        "            'Goodbye! Stay safe on the road.',\n",
        "            'Thanks for connecting! Catch you later.'\n",
        "        ],\n",
        "        'small_talk': [\n",
        "            'My day’s going smoothly, thanks! How’s yours?',\n",
        "            'Trucking life’s always moving! How’s it treating you?',\n",
        "            'Just keeping the wheels turning! Got any big plans?',\n",
        "            'All’s good here! What’s new with you?'\n",
        "        ],\n",
        "        'compliment': [\n",
        "            'Thanks, you’re awesome too! Need help with anything?',\n",
        "            'Appreciate that! What can I do for you today?'\n",
        "        ],\n",
        "        'weather_query': [\n",
        "            'Can’t see the skies, but I can check your route! Where are you headed?',\n",
        "            'Weather’s a mystery here, but I’m ready to help! What’s your destination?'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Create dialogue pairs\n",
        "    dialogues = []\n",
        "    for _, row in df_conversational.iterrows():\n",
        "        user_input = row['text']\n",
        "        intent = row['intent']\n",
        "        response = random.choice(response_map[intent])\n",
        "        dialogues.append({'input': user_input, 'response': response})\n",
        "\n",
        "    # Save as dataset\n",
        "    dialogue_df = pd.DataFrame(dialogues)\n",
        "    dataset = Dataset.from_pandas(dialogue_df)\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    dialogue_df.to_csv('data/dialoggpt_dialogues.csv', index=False)\n",
        "\n",
        "    print(f'DialogGPT training data prepared: {len(dialogue_df)} dialogue pairs.')\n",
        "    return dataset\n",
        "\n",
        "# Prepare data\n",
        "dialoggpt_dataset = prepare_dialoggpt_training_data(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Fine-Tune DialogGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fine_tune_dialoggpt(dataset):\n",
        "    model_name = 'microsoft/DialoGPT-medium'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    def preprocess_dialogues(examples):\n",
        "        # Concatenate input and response with a separator\n",
        "        conversations = [f\"{inp} <|endoftext|> {resp}\" for inp, resp in zip(examples['input'], examples['response'])]\n",
        "        tokenized = tokenizer(\n",
        "            conversations,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        tokenized['labels'] = tokenized['input_ids'].clone()\n",
        "        return tokenized\n",
        "\n",
        "    tokenized_dataset = dataset.map(preprocess_dialogues, batched=True)\n",
        "    tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./dialoggpt_results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./dialoggpt_logs',\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        eval_dataset=tokenized_dataset\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        trainer.train()\n",
        "        trainer.save_model('./dialoggpt_model')\n",
        "        tokenizer.save_pretrained('./dialoggpt_model')\n",
        "        print('DialogGPT model fine-tuned and saved.')\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f'Error fine-tuning DialogGPT: {e}')\n",
        "        return None, None\n",
        "\n",
        "# Fine-tune (use GPU if available; skip for quick testing)\n",
        "dialoggpt_model, dialoggpt_tokenizer = fine_tune_dialoggpt(dialoggpt_dataset)\n",
        "if dialoggpt_model is None:\n",
        "    print('Using pretrained DialogGPT due to fine-tuning error.')\n",
        "    dialoggpt_model = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-medium')\n",
        "    dialoggpt_tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Preprocess for DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "    \n",
        "    dataset = Dataset.from_pandas(df[['text', 'intent']])\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_dataset = tokenized_dataset.rename_column('intent', 'labels')\n",
        "    label_map = {label: idx for idx, label in enumerate(sorted(df['intent'].unique()))}\n",
        "    tokenized_dataset = tokenized_dataset.map(lambda x: {'labels': label_map[x['labels']]})\n",
        "    return tokenized_dataset, label_map, tokenizer\n",
        "\n",
        "# Preprocess\n",
        "dataset, label_map, tokenizer = preprocess_data(df)\n",
        "print(f'Label Map: {label_map}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train DistilBERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(dataset, label_map):\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_map))\n",
        "    train_dataset, eval_dataset = dataset.train_test_split(test_size=0.2).values()\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset\n",
        "    )\n",
        "    try:\n",
        "        trainer.train()\n",
        "        trainer.save_model('./chatbot_model')\n",
        "        return trainer, model, train_dataset, eval_dataset\n",
        "    except Exception as e:\n",
        "        print(f'Error training DistilBERT model: {e}')\n",
        "        return None, None, None, None\n",
        "\n",
        "# Train\n",
        "trainer, model, train_dataset, eval_dataset = train_model(dataset, label_map)\n",
        "if trainer is None:\n",
        "    raise RuntimeError('Failed to train DistilBERT model.')\n",
        "with open('label_map.json', 'w') as f:\n",
        "    json.dump(label_map, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(trainer, eval_dataset, label_map):\n",
        "    try:\n",
        "        predictions = trainer.predict(eval_dataset)\n",
        "        preds = np.argmax(predictions.predictions, axis=1)\n",
        "        labels = predictions.label_ids\n",
        "        accuracy = accuracy_score(labels, preds)\n",
        "        report = classification_report(labels, preds, target_names=label_map.keys())\n",
        "        print(f'Accuracy: {accuracy:.4f}')\n",
        "        print(f'Classification Report:\\n{report}\\n')\n",
        "        cm = confusion_matrix(labels, preds)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f'Error evaluating model: {e}')\n",
        "\n",
        "# Evaluate\n",
        "evaluate_model(trainer, eval_dataset, label_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Dialogue Management",
        "",
        "Hybrid dialogue management with DialogGPT and DistilBERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DialogueManager:\n",
        "    def __init__(self, model, tokenizer, label_map, dialoggpt_model, dialoggpt_tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dialoggpt_model = dialoggpt_model\n",
        "        self.dialoggpt_tokenizer = dialoggpt_tokenizer\n",
        "        self.reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "        self.state = 'INITIAL'\n",
        "        self.context = defaultdict(str)\n",
        "        self.history = []\n",
        "        self.fallback_responses = {\n",
        "            'greeting': {\n",
        "                'INITIAL': [\n",
        "                    'Hello! How can I assist you with your trucking needs today?',\n",
        "                    'Hi there! What can I help you with regarding your shipments or account?'\n",
        "                ],\n",
        "                'POST_GREETING': [\n",
        "                    'Thanks for the greeting! How can I assist with your shipment or billing needs?',\n",
        "                    'Nice to connect again! What’s on your mind today?'\n",
        "                ]\n",
        "            },\n",
        "            'farewell': {\n",
        "                'INITIAL': [\n",
        "                    'Goodbye! Feel free to reach out if you need further assistance.',\n",
        "                    'Thanks for connecting! Let me know if you have more questions later.'\n",
        "                ]\n",
        "            },\n",
        "            'small_talk': {\n",
        "                'INITIAL': {\n",
        "                    'mood': ['My day’s going smoothly, thanks for asking! How’s yours?'],\n",
        "                    'plans': ['No big plans here, just helping truckers! Got any big plans yourself?'],\n",
        "                    'industry': ['Trucking life’s always moving! How’s it treating you these days?'],\n",
        "                    'default': ['All’s well here, thanks for asking! Need help with your shipments?']\n",
        "                }\n",
        "            },\n",
        "            'compliment': {\n",
        "                'INITIAL': ['Thank you, that’s kind of you! How can I assist you today?']\n",
        "            },\n",
        "            'weather_query': {\n",
        "                'INITIAL': ['Weather’s clear here, but I can check for your route! Where are you headed?']\n",
        "            }\n",
        "        }\n",
        "        self.trucking_responses = {\n",
        "            'delivery_status': {\n",
        "                'INITIAL': 'I can check your shipment status for {location}. Please provide the shipment ID.',\n",
        "                'AWAITING_SHIPMENT_ID': 'Could you share the shipment ID to proceed with tracking?',\n",
        "                'PROVIDED_SHIPMENT_ID': 'Thank you. Shipment {shipment_id} is currently at {location}. Would you like the estimated arrival time?'\n",
        "            },\n",
        "            'billing_issue': {\n",
        "                'INITIAL': 'Let’s review your billing issue with {company}. Is this about an overcharge or a payment concern?',\n",
        "                'AWAITING_DETAILS': 'Can you provide the invoice number or {company} transaction amount?',\n",
        "                'RESOLVING': 'I’ve noted a ${amount} charge on your {company} invoice. Would you like to dispute this?'\n",
        "            },\n",
        "            'account_update': {\n",
        "                'INITIAL': 'I can help update your account details for {regulation}. What information would you like to change?',\n",
        "                'AWAITING_INFO': 'Please provide the new address or contact details for {regulation}.',\n",
        "                'CONFIRMING': 'I have {new_info} for your {regulation} update. Please confirm to proceed.'\n",
        "            },\n",
        "            'service_inquiry': {\n",
        "                'INITIAL': 'I can provide information on our services. Are you interested in flatbed, refrigerated, or bulk transport rates?',\n",
        "                'AWAITING_SPECIFICS': 'Which service are you inquiring about: flatbed, refrigerated, or bulk transport?'\n",
        "            },\n",
        "            'fuel_card_query': {\n",
        "                'INITIAL': 'I can assist with your {company} fuel card or {regulation} query. Is this about a balance, transaction, or compliance?',\n",
        "                'AWAITING_DETAILS': 'Could you specify if this is a {company} card issue or a {regulation} tax question?'\n",
        "            },\n",
        "            'general_query': {\n",
        "                'INITIAL': 'Could you clarify your request? I can help with delivery, billing, account updates, or {company}/{regulation} services.'\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def predict_intent(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "        return self.reverse_label_map[predicted_label]\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        entities = []\n",
        "        text = text.lower()\n",
        "        if 'speedway' in text:\n",
        "            entities.append({'entity': 'location', 'value': 'Speedway'})\n",
        "        if 'comdata' in text:\n",
        "            entities.append({'entity': 'company', 'value': 'Comdata'})\n",
        "        if 'ifta' in text:\n",
        "            entities.append({'entity': 'regulation', 'value': 'IFTA'})\n",
        "        import re\n",
        "        shipment_match = re.search(r'\\bship\\d+\\b', text, re.IGNORECASE)\n",
        "        if shipment_match:\n",
        "            entities.append({'entity': 'shipment_id', 'value': shipment_match.group()})\n",
        "        amount_match = re.search(r'\\$\\d+', text)\n",
        "        if amount_match:\n",
        "            entities.append({'entity': 'amount', 'value': amount_match.group()})\n",
        "        if 'new address' in text or 'change to' in text:\n",
        "            new_info = text.split('new address')[-1].strip() or text.split('change to')[-1].strip()\n",
        "            entities.append({'entity': 'new_info', 'value': new_info[:50]})\n",
        "        return entities\n",
        "\n",
        "    def get_dialoggpt_response(self, text):\n",
        "        try:\n",
        "            # Encode input with EOS token\n",
        "            input_ids = self.dialoggpt_tokenizer.encode(text + self.dialoggpt_tokenizer.eos_token, return_tensors='pt')\n",
        "            # Generate response\n",
        "            reply_ids = self.dialoggpt_model.generate(\n",
        "                input_ids,\n",
        "                max_length=1250,\n",
        "                pad_token_id=self.dialoggpt_tokenizer.eos_token_id,\n",
        "                no_repeat_ngram_size=3,\n",
        "                top_p=0.9,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            response = self.dialoggpt_tokenizer.decode(reply_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f'Error getting DialogGPT response: {e}')\n",
        "            return ''\n",
        "\n",
        "    def update_context(self, intent, entities, text):\n",
        "        self.history.append((intent, text, ''))\n",
        "        for entity in entities:\n",
        "            self.context[entity['entity']] = entity['value']\n",
        "        if intent == 'greeting':\n",
        "            self.context['greeted'] = 'true'\n",
        "        if intent == 'small_talk':\n",
        "            text = text.lower()\n",
        "            if 'day' in text or 'how’s your day' in text:\n",
        "                self.context['small_talk_type'] = 'mood'\n",
        "            elif 'plans' in text or 'big plans' in text:\n",
        "                self.context['small_talk_type'] = 'plans'\n",
        "            elif 'trucking' in text or 'truck' in text:\n",
        "                self.context['small_talk_type'] = 'industry'\n",
        "            else:\n",
        "                self.context['small_talk_type'] = 'default'\n",
        "\n",
        "    def transition_state(self, intent, entities, text):\n",
        "        if intent in ['greeting', 'small_talk', 'compliment', 'weather_query']:\n",
        "            self.state = 'POST_GREETING' if self.state == 'INITIAL' and intent == 'greeting' else self.state\n",
        "        elif intent == 'farewell':\n",
        "            self.state = 'INITIAL'\n",
        "        elif intent == 'delivery_status':\n",
        "            if self.state == 'INITIAL' and 'shipment_id' not in self.context:\n",
        "                self.state = 'AWAITING_SHIPMENT_ID'\n",
        "            elif 'shipment_id' in self.context:\n",
        "                self.state = 'PROVIDED_SHIPMENT_ID'\n",
        "        elif intent == 'billing_issue':\n",
        "            if self.state == 'INITIAL' and not any(e['entity'] in ['amount', 'transaction_id'] for e in entities):\n",
        "                self.state = 'AWAITING_DETAILS'\n",
        "            elif any(e['entity'] in ['amount', 'transaction_id'] for e in entities):\n",
        "                self.state = 'RESOLVING'\n",
        "        elif intent == 'account_update':\n",
        "            if self.state == 'INITIAL' and 'new_info' not in self.context:\n",
        "                self.state = 'AWAITING_INFO'\n",
        "            elif 'new_info' in self.context:\n",
        "                self.state = 'CONFIRMING'\n",
        "        elif intent == 'service_inquiry':\n",
        "            if self.state == 'INITIAL' and 'service_type' not in self.context:\n",
        "                self.state = 'AWAITING_SPECIFICS'\n",
        "        elif intent == 'fuel_card_query':\n",
        "            if self.state == 'INITIAL' and not any(e['entity'] in ['balance', 'transaction'] for e in entities):\n",
        "                self.state = 'AWAITING_DETAILS'\n",
        "\n",
        "    def generate_response(self, intent, entities, text):\n",
        "        self.update_context(intent, entities, text)\n",
        "        self.transition_state(intent, entities, text)\n",
        "\n",
        "        if intent in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']:\n",
        "            # Use DialogGPT for conversational intents\n",
        "            dialoggpt_response = self.get_dialoggpt_response(text)\n",
        "            # Filter inappropriate responses\n",
        "            if not dialoggpt_response or len(dialoggpt_response) < 5 or any(word in dialoggpt_response.lower() for word in ['inappropriate', 'sorry', 'weird']):\n",
        "                if intent == 'small_talk':\n",
        "                    small_talk_type = self.context.get('small_talk_type', 'default')\n",
        "                    response_options = self.fallback_responses[intent]['INITIAL'].get(small_talk_type, self.fallback_responses[intent]['INITIAL']['default'])\n",
        "                else:\n",
        "                    response_options = self.fallback_responses.get(intent, {'INITIAL': ['Could you clarify your request?']}).get(self.state, self.fallback_responses[intent].get('INITIAL'))\n",
        "                response = random.choice(response_options) if isinstance(response_options, list) else response_options\n",
        "            else:\n",
        "                response = dialoggpt_response + ' Need help with your trucking needs?'\n",
        "            # Time-aware greeting\n",
        "            if intent == 'greeting' and 'good morning' in text.lower() and datetime.now().hour < 12:\n",
        "                response = random.choice(['Good morning to you too! How can I assist today?', 'Morning! Ready to help with your trucking needs.'])\n",
        "        else:\n",
        "            # Use DistilBERT for trucking intents\n",
        "            response_template = self.trucking_responses.get(intent, self.trucking_responses['general_query']).get(self.state, self.trucking_responses[intent]['INITIAL'])\n",
        "            response = response_template.format(**{k: v for k, v in self.context.items() if k in ['location', 'company', 'regulation', 'shipment_id', 'amount', 'new_info']},\n",
        "                                               **{'location': 'unknown', 'company': 'unknown', 'regulation': 'unknown', 'shipment_id': 'unknown', 'amount': 'unknown', 'new_info': 'unknown'})\n",
        "\n",
        "        if self.context.get('greeted') == 'true' and intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'] and 'POST_GREETING' not in self.state:\n",
        "            response = f'Since you greeted me earlier, I’m ready to help! {response}'\n",
        "\n",
        "        self.history[-1] = (intent, text, response)\n",
        "        resolved = self.state in ['PROVIDED_SHIPMENT_ID', 'RESOLVING', 'CONFIRMING'] and intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "        return response, resolved\n",
        "\n",
        "    def evaluate_dialogue_success(self):\n",
        "        resolved = sum(1 for intent, _, _ in self.history if self.state in ['PROVIDED_SHIPMENT_ID', 'RESOLVING', 'CONFIRMING'] and intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'])\n",
        "        total = len([i for i, _, _ in self.history if i not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']])\n",
        "        return resolved / total if total > 0 else 0\n",
        "\n",
        "# Initialize dialogue manager\n",
        "try:\n",
        "    with open('label_map.json', 'r') as f:\n",
        "        label_map = json.load(f)\n",
        "    dialogue_manager = DialogueManager(model, tokenizer, label_map, dialoggpt_model, dialoggpt_tokenizer)\n",
        "except FileNotFoundError:\n",
        "    print('Error: label_map.json not found. Please train the DistilBERT model first.')\n",
        "    dialogue_manager = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Interactive Chatbot UI",
        "",
        "UI with DialogGPT conversational support trained on Twitter data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if dialogue_manager is None:\n",
        "    print('Dialogue manager not initialized. Please fix previous errors.')\n",
        "else:\n",
        "    # Create UI\n",
        "    input_box = widgets.Text(\n",
        "        value='',\n",
        "        placeholder='Type your query (e.g., Hello, How’s your day?, or Where’s my shipment?)',\n",
        "        description='Query:',\n",
        "        layout={'width': '500px'}\n",
        "    )\n",
        "    submit_button = widgets.Button(\n",
        "        description='Submit',\n",
        "        button_style='primary',\n",
        "        tooltip='Submit query'\n",
        "    )\n",
        "    follow_up_button1 = widgets.Button(\n",
        "        description='Request ETA',\n",
        "        button_style='info',\n",
        "        tooltip='Request ETA',\n",
        "        layout={'visibility': 'hidden'}\n",
        "    )\n",
        "    follow_up_button2 = widgets.Button(\n",
        "        description='Confirm',\n",
        "        button_style='success',\n",
        "        tooltip='Confirm action',\n",
        "        layout={'visibility': 'hidden'}\n",
        "    )\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    def on_submit_button_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            user_input = input_box.value.strip()\n",
        "            if not user_input:\n",
        "                print('Please enter a query.')\n",
        "                return\n",
        "            print(f'You: {user_input}')\n",
        "            try:\n",
        "                intent = dialogue_manager.predict_intent(user_input)\n",
        "                entities = dialogue_manager.extract_entities(user_input)\n",
        "                response, resolved = dialogue_manager.generate_response(intent, entities, user_input)\n",
        "                print(f'Bot: {response}')\n",
        "                input_box.value = ''\n",
        "                follow_up_button1.layout.visibility = 'visible' if dialogue_manager.state == 'PROVIDED_SHIPMENT_ID' else 'hidden'\n",
        "                follow_up_button2.layout.visibility = 'visible' if dialogue_manager.state in ['RESOLVING', 'CONFIRMING'] else 'hidden'\n",
        "                success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "                print(f'Dialogue Success Rate: {success_rate:.2f}' if success_rate > 0 else 'Dialogue Success Rate: N/A (conversational only)')\n",
        "            except Exception as e:\n",
        "                print(f'Error processing query: {e}')\n",
        "\n",
        "    def on_follow_up_button1_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            user_input = 'Provide the ETA'\n",
        "            print(f'You: {user_input}')\n",
        "            try:\n",
        "                intent = dialogue_manager.predict_intent(user_input)\n",
        "                entities = dialogue_manager.extract_entities(user_input)\n",
        "                response = f'The estimated arrival time for shipment {dialogue_manager.context.get(\"shipment_id\", \"unknown\")} is tomorrow by 3 PM.'\n",
        "                dialogue_manager.history.append((intent, user_input, response))\n",
        "                print(f'Bot: {response}')\n",
        "                follow_up_button1.layout.visibility = 'hidden'\n",
        "                success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "                print(f'Dialogue Success Rate: {success_rate:.2f}' if success_rate > 0 else 'Dialogue Success Rate: N/A (conversational only)')\n",
        "            except Exception as e:\n",
        "                print(f'Error processing follow-up: {e}')\n",
        "\n",
        "    def on_follow_up_button2_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            user_input = 'Confirm'\n",
        "            print(f'You: {user_input}')\n",
        "            try:\n",
        "                intent = dialogue_manager.predict_intent(user_input)\n",
        "                entities = dialogue_manager.extract_entities(user_input)\n",
        "                response = f'Confirmed. {dialogue_manager.context.get(\"new_info\", \"Action\")} has been updated.' if dialogue_manager.state == 'CONFIRMING' else f'Dispute for {dialogue_manager.context.get(\"amount\", \"unknown\")} has been submitted.'\n",
        "                dialogue_manager.history.append((intent, user_input, response))\n",
        "                dialogue_manager.state = 'INITIAL'\n",
        "                print(f'Bot: {response}')\n",
        "                follow_up_button2.layout.visibility = 'hidden'\n",
        "                success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "                print(f'Dialogue Success Rate: {success_rate:.2f}' if success_rate > 0 else 'Dialogue Success Rate: N/A (conversational only)')\n",
        "            except Exception as e:\n",
        "                print(f'Error processing follow-up: {e}')\n",
        "\n",
        "    submit_button.on_click(on_submit_button_clicked)\n",
        "    follow_up_button1.on_click(on_follow_up_button1_clicked)\n",
        "    follow_up_button2.on_click(on_follow_up_button2_clicked)\n",
        "\n",
        "    # Display UI\n",
        "    display(widgets.VBox([\n",
        "        widgets.HTML('<h3>Trucking Co. Chatbot</h3>'),\n",
        "        input_box,\n",
        "        submit_button,\n",
        "        follow_up_button1,\n",
        "        follow_up_button2,\n",
        "        output_area\n",
        "    ]))\n",
        "    print('Welcome! You can greet me, chat about your day, or ask about delivery, billing, account updates, or Comdata/IFTA services.')\n",
        "    print('Type your query and click Submit.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}