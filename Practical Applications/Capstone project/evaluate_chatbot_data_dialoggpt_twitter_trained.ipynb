{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Customer Service Chatbot with DialogGPT for Conversational Intents\n",
        "\n",
        "This Jupyter Notebook updates `evaluate_chatbot_data_dialoggpt_twitter_trained.ipynb` to use the latest module versions (as of May 29, 2025) for a trucking company chatbot, fixing syntax errors. It uses Microsoft’s DialogGPT for conversational intents (greeting, farewell, small_talk, compliment, weather_query) and DistilBERT for trucking-specific intents (delivery_status, billing_issue, account_update, service_inquiry, fuel_card_query, general_query). Trains on Twitter dataset (`tweets.csv` or `trucking_chatbot_test_dataset.csv`) with interactive ipywidgets UI.\n",
        "\n",
        "## Objectives\n",
        "- Inspect Twitter dataset for intents and entities (e.g., location, company).\n",
        "- Train DistilBERT for intent classification.\n",
        "- Fine-tune DialogGPT on conversational Twitter data.\n",
        "- Evaluate DistilBERT with accuracy, F1-score, confusion matrix, and dialogue success rate.\n",
        "- Implement hybrid dialogue management with DialogGPT and DistilBERT.\n",
        "- Provide interactive UI for customer interaction.\n",
        "\n",
        "## Requirements\n",
        "- Python 3.8 (recommended; 3.9 also compatible)\n",
        "- Install: `pip install transformers==4.44.2 torch==2.5.0 pandas==2.2.3 numpy==2.1.1 scikit-learn==1.5.2 datasets==3.0.1 seaborn==0.13.2 matplotlib==3.9.2 ipywidgets==8.1.5`\n",
        "- For GPU: `pip install torch==2.5.0+cu121 --index-url https://download.pytorch.org/whl/cu121`\n",
        "- Place `trucking_chatbot_test_dataset.csv` or `tweets.csv` in the directory.\n",
        "- Enable widgets: `jupyter nbextension enable --py widgetsnbextension`\n",
        "\n",
        "## Notes\n",
        "- Dataset: https://www.kaggle.com/thoughtvector/customer-support-on-twitter\n",
        "- Reflects tariffs/Moody’s downgrade in billing/fuel inquiries.\n",
        "- Professional responses with dynamic DialogGPT conversation.\n",
        "- Date: May 29, 2025, 11:56 AM EDT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import re\n",
        "from datetime import datetime\n",
        "import os\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Inspect and Preprocess Dataset\n",
        "\n",
        "Load Twitter dataset, add conversational examples, label intents/entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inspect_dataset(file_path='trucking_chatbot_test_dataset.csv'):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print('Dataset not found. Using Twitter dataset.')\n",
        "        try:\n",
        "            df = pd.read_csv('tweets.csv')\n",
        "        except FileNotFoundError:\n",
        "            print('Download from: https://www.kaggle.com/thoughtvector/customer-support-on-twitter')\n",
        "            data = {\n",
        "                'text': [\n",
        "                    'Where is my shipment from Speedway?',\n",
        "                    'Why is my Comdata bill so high?',\n",
        "                    'Need to update my address for IFTA',\n",
        "                    'What are your hauling rates?',\n",
        "                    'Help with my account',\n",
        "                    'Hello',\n",
        "                    'How are you',\n",
        "                    'How can I help you',\n",
        "                    'Track my cargo',\n",
        "                    'Overcharged on Comdata invoice',\n",
        "                    'Hi there',\n",
        "                    'Change my contact info',\n",
        "                    'Tell me about Comdata services',\n",
        "                    'Lost my shipment',\n",
        "                    'Good morning',\n",
        "                    'Thanks for your help',\n",
        "                    'Bye',\n",
        "                    'What’s new?',\n",
        "                    'How’s it going?',\n",
        "                    'How’s your day going?',\n",
        "                    'Any big plans?',\n",
        "                    'How’s the trucking life?',\n",
        "                    'You’re awesome!',\n",
        "                    'Great job!',\n",
        "                    'How’s the weather there?',\n",
        "                    'Is it raining?'\n",
        "                ],\n",
        "                'intent': [\n",
        "                    'delivery_status',\n",
        "                    'billing_issue',\n",
        "                    'account_update',\n",
        "                    'service_inquiry',\n",
        "                    'general_query',\n",
        "                    'greeting',\n",
        "                    'greeting',\n",
        "                    'greeting',\n",
        "                    'delivery_status',\n",
        "                    'billing_issue',\n",
        "                    'greeting',\n",
        "                    'account_update',\n",
        "                    'fuel_card_query',\n",
        "                    'general_query',\n",
        "                    'greeting',\n",
        "                    'farewell',\n",
        "                    'farewell',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'small_talk',\n",
        "                    'compliment',\n",
        "                    'compliment',\n",
        "                    'weather_query',\n",
        "                    'weather_query'\n",
        "                ]\n",
        "            }\n",
        "            df = pd.DataFrame(data)\n",
        "\n",
        "    keywords = ['delivery', 'shipment', 'cargo', 'bill', 'invoice', 'payment', 'account', 'service', 'hauling', 'truck', 'comdata', 'ifta', 'speedway', 'fuel', 'tax', 'station', 'hello', 'hi', 'how', 'good', 'bye', 'thanks', 'new', 'day', 'plans', 'awesome', 'great', 'weather', 'rain']\n",
        "    if 'text' in df.columns:\n",
        "        df = df[df['text'].str.contains('|'.join(keywords), case=False, na=False)]\n",
        "        df = df.sample(n=min(10000, len(df)), random_state=42)\n",
        "\n",
        "    if 'intent' not in df.columns:\n",
        "        def label_intent(text):\n",
        "            text = text.lower()\n",
        "            if any(word in text for word in ['hello', 'hi', 'how are you', 'how can i help', 'good morning', 'good afternoon']):\n",
        "                return 'greeting'\n",
        "            elif any(word in text for word in ['goodbye', 'bye', 'thanks', 'thank you']):\n",
        "                return 'farewell'\n",
        "            elif any(word in text for word in ['what’s new', 'how’s it going', 'how’s your day', 'any big plans', 'trucking life']):\n",
        "                return 'small_talk'\n",
        "            elif any(word in text for word in ['awesome', 'great job', 'you rock']):\n",
        "                return 'compliment'\n",
        "            elif any(word in text for word in ['weather', 'rain', 'sunny']):\n",
        "                return 'weather_query'\n",
        "            elif any(word in text for word in ['delivery', 'shipment', 'track', 'cargo']):\n",
        "                return 'delivery_status'\n",
        "            elif any(word in text for word in ['bill', 'invoice', 'payment', 'charge']):\n",
        "                return 'billing_issue'\n",
        "            elif any(word in text for word in ['update', 'change', 'address', 'contact']):\n",
        "                return 'account_update'\n",
        "            elif any(word in text for word in ['service', 'rate', 'hauling']):\n",
        "                return 'service_inquiry'\n",
        "            elif any(word in text for word in ['comdata', 'ifta', 'fuel', 'tax']):\n",
        "                return 'fuel_card_query'\n",
        "            else:\n",
        "                return 'general_query'\n",
        "        df['intent'] = df['text'].apply(label_intent)\n",
        "\n",
        "    def extract_entities(text):\n",
        "        entities = []\n",
        "        text = text.lower()\n",
        "        if 'speedway' in text:\n",
        "            entities.append({'entity': 'location', 'value': 'Speedway'})\n",
        "        if 'comdata' in text:\n",
        "            entities.append({'entity': 'company', 'value': 'Comdata'})\n",
        "        if 'ifta' in text:\n",
        "            entities.append({'entity': 'regulation', 'value': 'IFTA'})\n",
        "        return entities\n",
        "\n",
        "    df['entities'] = df['text'].apply(extract_entities)\n",
        "\n",
        "    print('Dataset Shape:', df.shape)\n",
        "    print('Columns:', df.columns.tolist())\n",
        "    print('Sample Rows:\\n', df.head())\n",
        "    print('Missing Values:\\n', df.isnull().sum())\n",
        "    print('Intent Distribution:\\n', df['intent'].value_counts())\n",
        "    print('Entity Samples:\\n', df[df['entities'].apply(len) > 0][['text', 'entities']].head())\n",
        "    return df\n",
        "\n",
        "df = inspect_dataset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Prepare DialogGPT Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dialoggpt_training_data(df):\n",
        "    conversational_intents = ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "    df_conversational = df[df['intent'].isin(conversational_intents)][['text', 'intent']]\n",
        "\n",
        "    response_map = {\n",
        "        'greeting': [\n",
        "            'Hello! How can I assist you with your trucking needs today?',\n",
        "            'Hi there! Ready to help with your shipments or account!',\n",
        "            'Good to hear from you! What’s up?'\n",
        "        ],\n",
        "        'farewell': [\n",
        "            'Goodbye! Stay safe on the road.',\n",
        "            'Thanks for connecting! Catch you later.'\n",
        "        ],\n",
        "        'small_talk': [\n",
        "            'My day’s going smoothly, thanks! How’s yours?',\n",
        "            'Trucking life’s always moving! How’s it treating you?',\n",
        "            'Just keeping the wheels turning! Got any big plans?',\n",
        "            'All’s good here! What’s new with you?'\n",
        "        ],\n",
        "        'compliment': [\n",
        "            'Thanks, you’re awesome too! Need help with anything?',\n",
        "            'Appreciate that! What can I do for you today?'\n",
        "        ],\n",
        "        'weather_query': [\n",
        "            'Can’t see the skies, but I can check your route! Where are you headed?',\n",
        "            'Weather’s a mystery here, but I’m ready to help! What’s your destination?'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    dialogues = []\n",
        "    for _, row in df_conversational.iterrows():\n",
        "        user_input = row['text']\n",
        "        intent = row['intent']\n",
        "        response = random.choice(response_map[intent])\n",
        "        dialogues.append({'input': user_input, 'response': response})\n",
        "\n",
        "    dialogue_df = pd.DataFrame(dialogues)\n",
        "    dataset = Dataset.from_pandas(dialogue_df)\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    dialogue_df.to_csv('data/dialoggpt_dialogues.csv', index=False)\n",
        "\n",
        "    print(f'DialogGPT training data prepared: {len(dialogue_df)} dialogue pairs.')\n",
        "    return dataset\n",
        "\n",
        "dialoggpt_dataset = prepare_dialoggpt_training_data(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Fine-Tune DialogGPT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fine_tune_dialoggpt(dataset):\n",
        "    model_name = 'microsoft/DialoGPT-medium'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Fix padding token\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    def preprocess_dialogues(examples):\n",
        "        conversations = [f\"{inp} {tokenizer.eos_token} {resp}\" for inp, resp in zip(examples['input'], examples['response'])]\n",
        "        tokenized = tokenizer(\n",
        "            conversations,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        tokenized['labels'] = tokenized['input_ids'].clone()\n",
        "        return tokenized\n",
        "\n",
        "    tokenized_dataset = dataset.map(preprocess_dialogues, batched=True)\n",
        "    tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./dialoggpt_results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./dialoggpt_logs',\n",
        "        logging_steps=10,\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=0\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        eval_dataset=tokenized_dataset\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        trainer.train()\n",
        "        trainer.save_model('./dialoggpt_model')\n",
        "        tokenizer.save_pretrained('./dialoggpt_model')\n",
        "        print('DialogGPT model fine-tuned and saved.')\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f'Error fine-tuning DialogGPT: {e}')\n",
        "        return None, None\n",
        "\n",
        "dialoggpt_model, dialoggpt_tokenizer = fine_tune_dialoggpt(dialoggpt_dataset)\n",
        "if dialoggpt_model is None:\n",
        "    print('Using pretrained DialogGPT due to fine-tuning error.')\n",
        "    dialoggpt_model = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-medium')\n",
        "    dialoggpt_tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')\n",
        "    dialoggpt_tokenizer.pad_token = dialoggpt_tokenizer.eos_token\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Preprocess for DistilBERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "    \n",
        "    dataset = Dataset.from_pandas(df[['text', 'intent']])\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_dataset = tokenized_dataset.rename_column('intent', 'labels')\n",
        "    label_map = {label: idx for idx, label in enumerate(sorted(df['intent'].unique()))}\n",
        "    tokenized_dataset = tokenized_dataset.map(lambda x: {'labels': label_map[x['labels']]})\n",
        "    return tokenized_dataset, label_map, tokenizer\n",
        "\n",
        "dataset, label_map, tokenizer = preprocess_data(df)\n",
        "print(f'Label Map: {label_map}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train DistilBERT Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(dataset, label_map):\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_map))\n",
        "    train_dataset, eval_dataset = dataset.train_test_split(test_size=0.2).values()\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=0\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset\n",
        "    )\n",
        "    try:\n",
        "        trainer.train()\n",
        "        trainer.save_model('./chatbot_model')\n",
        "        return trainer, model, train_dataset, eval_dataset\n",
        "    except Exception as e:\n",
        "        print(f'Error training DistilBERT model: {e}')\n",
        "        return None, None, None, None\n",
        "\n",
        "trainer, model, train_dataset, eval_dataset = train_model(dataset, label_map)\n",
        "if trainer is None:\n",
        "    raise RuntimeError('Failed to train DistilBERT model.')\n",
        "with open('label_map.json', 'w') as f:\n",
        "    json.dump(label_map, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(trainer, eval_dataset, label_map):\n",
        "    try:\n",
        "        predictions = trainer.predict(eval_dataset)\n",
        "        preds = np.argmax(predictions.predictions, axis=1)\n",
        "        labels = predictions.label_ids\n",
        "        accuracy = accuracy_score(labels, preds)\n",
        "        report = classification_report(labels, preds, target_names=label_map.keys())\n",
        "        print(f'Accuracy: {accuracy:.4f}')\n",
        "        print(f'Classification Report:\\n{report}\\n')\n",
        "        cm = confusion_matrix(labels, preds)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f'Error evaluating model: {e}')\n",
        "\n",
        "evaluate_model(trainer, eval_dataset, label_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Dialogue Management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DialogueManager:\n",
        "    def __init__(self, model, tokenizer, label_map, dialoggpt_model, dialoggpt_tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dialoggpt_model = dialoggpt_model\n",
        "        self.dialoggpt_tokenizer = dialoggpt_tokenizer\n",
        "        self.reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "        self.state = 'INITIAL'\n",
        "        self.context = defaultdict(str)\n",
        "        self.history = []\n",
        "        self.fallback_responses = {\n",
        "            'greeting': {\n",
        "                'INITIAL': [\n",
        "                    'Hello! How can I assist you with your trucking needs today?',\n",
        "                    'Hi there! What can I help you with regarding your shipments or account?'\n",
        "                ],\n",
        "                'POST_GREETING': [\n",
        "                    'Thanks for the greeting! How can I assist with your shipment or billing needs?',\n",
        "                    'Nice to connect again! What’s on your mind today?'\n",
        "                ]\n",
        "            },\n",
        "            'farewell': {\n",
        "                'INITIAL': [\n",
        "                    'Goodbye! Feel free to reach out if you need further assistance.',\n",
        "                    'Thanks for connecting! Let me know if you have more questions later.'\n",
        "                ]\n",
        "            },\n",
        "            'small_talk': {\n",
        "                'INITIAL': {\n",
        "                    'mood': ['My day’s going smoothly, thanks for asking! How’s yours?'],\n",
        "                    'plans': ['No big plans here, just helping truckers! Got any big plans yourself?'],\n",
        "                    'industry': ['Trucking life’s always moving! How’s it treating you these days?'],\n",
        "                    'default': ['All’s well here, thanks for asking! Need help with your shipments?']\n",
        "                }\n",
        "            },\n",
        "            'compliment': {\n",
        "                'INITIAL': ['Thank you, that’s kind of you! How can I assist you today?']\n",
        "            },\n",
        "            'weather_query': {\n",
        "                'INITIAL': ['Weather’s clear here, but I can check for your route! Where are you headed?']\n",
        "            }\n",
        "        }\n",
        "        self.trucking_responses = {\n",
        "            'delivery_status': {\n",
        "                'INITIAL': 'I can check your shipment status for {location}. Please provide the shipment ID.',\n",
        "                'AWAITING_SHIPMENT_ID': 'Could you share the shipment ID to proceed with tracking?',\n",
        "                'PROVIDED_SHIPMENT_ID': 'Thank you. Shipment {shipment_id} is currently at {location}. Would you like the estimated arrival time?'\n",
        "            },\n",
        "            'billing_issue': {\n",
        "                'INITIAL': 'Let’s review your billing issue with {company}. Is this about an overcharge or a payment concern?',\n",
        "                'AWAITING_DETAILS': 'Can you provide the invoice number or {company} transaction amount?',\n",
        "                'RESOLVING': 'I’ve noted a {amount} charge on your {company} invoice. Would you like to dispute this?'\n",
        "            },\n",
        "            'account_update': {\n",
        "                'INITIAL': 'I can help update your account details for {regulation}. What information would you like to change?',\n",
        "                'AWAITING_INFO': 'Please provide the new address or contact details for {regulation}.',\n",
        "                'CONFIRMING': 'I have {new_info} for your {regulation} update. Please confirm to proceed.'\n",
        "            },\n",
        "            'service_inquiry': {\n",
        "                'INITIAL': 'I can provide information on our services. Are you interested in flatbed, refrigerated, or bulk transport rates?',\n",
        "                'AWAITING_SPECIFICS': 'Which service are you inquiring about: flatbed, refrigerated, or bulk transport?'\n",
        "            },\n",
        "            'fuel_card_query': {\n",
        "                'INITIAL': 'I can assist with your {company} fuel card or {regulation} query. Is this about a balance, transaction, or compliance?',\n",
        "                'AWAITING_DETAILS': 'Could you specify if this is a {company} card issue or a {regulation} tax question?'\n",
        "            },\n",
        "            'general_query': {\n",
        "                'INITIAL': 'Could you clarify your request? I can help with delivery, billing, account updates, or {company}/{regulation} services.'\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def predict_intent(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "        return self.reverse_label_map[predicted_label]\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        entities = []\n",
        "        text = text.lower()\n",
        "        if 'speedway' in text:\n",
        "            entities.append({'entity': 'location', 'value': 'Speedway'})\n",
        "        if 'comdata' in text:\n",
        "            entities.append({'entity': 'company', 'value': 'Comdata'})\n",
        "        if 'ifta' in text:\n",
        "            entities.append({'entity': 'regulation', 'value': 'IFTA'})\n",
        "        shipment_match = re.search(r'\\bship\\d+\\b', text, re.IGNORECASE)\n",
        "        if shipment_match:\n",
        "            entities.append({'entity': 'shipment_id', 'value': shipment_match.group()})\n",
        "        amount_match = re.search(r'\\$\\d+', text)\n",
        "        if amount_match:\n",
        "            entities.append({'entity': 'amount', 'value': amount_match.group()})\n",
        "        if 'new address' in text or 'change to' in text:\n",
        "            new_info = text.split('new address')[-1].strip() or text.split('change to')[-1].strip()\n",
        "            entities.append({'entity': 'new_info', 'value': new_info[:50]})\n",
        "        return entities\n",
        "\n",
        "    def get_dialoggpt_response(self, text):\n",
        "        try:\n",
        "            if self.dialoggpt_tokenizer.pad_token is None:\n",
        "                self.dialoggpt_tokenizer.pad_token = self.dialoggpt_tokenizer.eos_token\n",
        "            input_ids = self.dialoggpt_tokenizer.encode(text + self.dialoggpt_tokenizer.eos_token, return_tensors='pt')\n",
        "            reply_ids = self.dialoggpt_model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=128,\n",
        "                pad_token_id=self.dialoggpt_tokenizer.eos_token_id,\n",
        "                no_repeat_ngram_size=3,\n",
        "                top_p=0.9,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            response = self.dialoggpt_tokenizer.decode(reply_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f'Error getting DialogGPT response: {e}')\n",
        "            return None\n",
        "\n",
        "    def update_context(self, intent, entities, text):\n",
        "        self.history.append((intent, text, ''))\n",
        "        for entity in entities:\n",
        "            self.context[entity['entity']] = entity['value']\n",
        "        if intent == 'greeting':\n",
        "            self.context['greeted'] = 'true'\n",
        "        if intent == 'small_talk':\n",
        "            text = text.lower()\n",
        "            if 'day' in text or 'how’s your day' in text:\n",
        "                self.context['small_talk_type'] = 'mood'\n",
        "            elif 'plans' in text or 'big plans' in text:\n",
        "                self.context['small_talk_type'] = 'plans'\n",
        "            elif 'trucking' in text or 'truck' in text:\n",
        "                self.context['small_talk_type'] = 'industry'\n",
        "            else:\n",
        "                self.context['small_talk_type'] = 'default'\n",
        "\n",
        "    def transition_state(self, intent, entities, text):\n",
        "        if intent in ['greeting', 'small_talk', 'compliment', 'weather_query']:\n",
        "            self.state = 'POST_GREETING' if self.state == 'INITIAL' and intent == 'greeting' else self.state\n",
        "        elif intent == 'farewell':\n",
        "            self.state = 'INITIAL'\n",
        "        elif intent == 'delivery_status':\n",
        "            if self.state == 'INITIAL' and 'shipment_id' not in self.context:\n",
        "                self.state = 'AWAITING_SHIPMENT_ID'\n",
        "            elif 'shipment_id' in self.context:\n",
        "                self.state = 'PROVIDED_SHIPMENT_ID'\n",
        "        elif intent == 'billing_issue':\n",
        "            if self.state == 'INITIAL' and not any(e['entity'] in ['amount', 'transaction_id'] for e in entities):\n",
        "                self.state = 'AWAITING_DETAILS'\n",
        "            elif any(e['entity'] in ['amount', 'transaction_id'] for e in entities):\n",
        "                self.state = 'RESOLVING'\n",
        "        elif intent == 'account_update':\n",
        "            if self.state == 'INITIAL' and 'new_info' not in self.context:\n",
        "                self.state = 'AWAITING_INFO'\n",
        "            elif 'new_info' in self.context:\n",
        "                self.state = 'CONFIRMING'\n",
        "        elif intent == 'service_inquiry':\n",
        "            if self.state == 'INITIAL' and 'service_type' not in self.context:\n",
        "                self.state = 'AWAITING_SPECIFICS'\n",
        "        elif intent == 'fuel_card_query':\n",
        "            if self.state == 'INITIAL' and not any(e['entity'] in ['balance', 'transaction'] for e in entities):\n",
        "                self.state = 'AWAITING_DETAILS'\n",
        "\n",
        "    def generate_response(self, intent, entities, text):\n",
        "        self.update_context(intent, entities, text)\n",
        "        self.transition_state(intent, entities, text)\n",
        "\n",
        "        if intent in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']:\n",
        "            dialog_response = self.get_dialoggpt_response(text)\n",
        "            if not dialog_response or len(dialog_response) < 5 or any(word in dialog_response.lower() for word in ['inappropriate', 'sorry', 'weird', 'lol']):\n",
        "                small_talk_type = self.context.get('small_talk_type', 'default')\n",
        "                if intent == 'small_talk':\n",
        "                    response_options = self.fallback_responses[intent]['INITIAL'].get(small_talk_type, self.fallback_responses[intent]['INITIAL']['default'])\n",
        "                else:\n",
        "                    response_options = self.fallback_responses.get(intent, {'INITIAL': ['Could you clarify your request?']}).get(self.state, self.fallback_responses[intent]['INITIAL'])\n",
        "                response = random.choice(response_options) if isinstance(response_options, list) else response_options\n",
        "            else:\n",
        "                response = dialog_response + ' Need assistance with your trucking needs?'\n",
        "            if intent == 'greeting' and 'good morning' in text.lower() and datetime.now().hour < 12:\n",
        "                response = random.choice(['Good morning to you too! How can I assist today?', 'Morning! Ready to help with your trucking needs.'])\n",
        "        else:\n",
        "            response_template = self.trucking_responses.get(intent, self.trucking_responses['general_query']).get(self.state, self.trucking_responses[intent]['INITIAL'])\n",
        "            try:\n",
        "                response = response_template.format(\n",
        "                    location=self.context.get('location', 'unknown'),\n",
        "                    company=self.context.get('company', 'unknown'),\n",
        "                    regulation=self.context.get('regulation', 'unknown'),\n",
        "                    shipment_id=self.context.get('shipment_id', 'unknown'),\n",
        "                    amount=self.context.get('amount', 'unknown'),\n",
        "                    new_info=self.context.get('new_info', 'unknown')\n",
        "                )\n",
        "            except KeyError:\n",
        "                response = response_template\n",
        "\n",
        "        if self.context.get('greeted') == 'true' and intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'] and 'PROVIDED' in self.state:\n",
        "            response = f'Since you greeted me earlier, I’m ready to assist! {response}'\n",
        "\n",
        "        self.history[-1] = (intent, text, response)\n",
        "        resolved = self.state in ['PROVIDED_SHIPMENT_ID', 'RESOLVING', 'CONFIRMING'] and intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "        return response, resolved\n",
        "\n",
        "    def evaluate_dialogue_success(self):\n",
        "        resolved = sum(1 for intent, _, _ in self.history if intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'] and self.state in ['PROVIDED_SHIPMENT_ID', 'RESOLVING', 'CONFIRMING'])\n",
        "        total = sum(1 for intent, _, _ in self.history if intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'])\n",
        "        return resolved / total if total > 0 else 0.0\n",
        "\n",
        "try:\n",
        "    with open('label_map.json', 'r') as f:\n",
        "        label_map = json.load(f)\n",
        "    dialogue_manager = DialogueManager(model, tokenizer, label_map, dialoggpt_model, dialoggpt_tokenizer)\n",
        "except FileNotFoundError:\n",
        "    print('Error: label_map.json not found. Please ensure Cell 6 has run successfully.')\n",
        "    dialogue_manager = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Interactive Chatbot UI\n",
        "\n",
        "UI with DialogGPT conversational support trained on Twitter data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if dialogue_manager is None:\n",
        "    print('Dialogue manager not initialized. Please fix previous errors.')\n",
        "else:\n",
        "    # Create UI\n",
        "    input_box = widgets.Text(\n",
        "        value='',\n",
        "        placeholder='Type your query (e.g., Hello, How’s your day?, or Where’s my shipment?)',\n",
        "        description='Query:',\n",
        "        layout={'width': '500px'}\n",
        "    )\n",
        "    submit_button = widgets.Button(\n",
        "        description='Submit',\n",
        "        button_style='success',\n",
        "        tooltip='Submit query'\n",
        "    )\n",
        "    follow_up_button1 = widgets.Button(\n",
        "        description='Request ETA',\n",
        "        button_style='info',\n",
        "        tooltip='Request ETA',\n",
        "        layout={'visibility': 'hidden'}\n",
        "    )\n",
        "    follow_up_button2 = widgets.Button(\n",
        "        description='Confirm',\n",
        "        button_style='success',\n",
        "        tooltip='Confirm action',\n",
        "        layout={'visibility': 'hidden'}\n",
        "    )\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    def on_submit_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            user_input = input_box.value.strip()\n",
        "            if not user_input:\n",
        "                print('Please enter a query.')\n",
        "                return\n",
        "            print(f'You: {user_input}')\n",
        "            try:\n",
        "                intent = dialogue_manager.predict_intent(user_input)\n",
        "                entities = dialogue_manager.extract_entities(user_input)\n",
        "                response, resolved = dialogue_manager.generate_response(intent, entities, user_input)\n",
        "                print(f'Bot: {response}')\n",
        "                input_box.value = ''\n",
        "                follow_up_button1.layout.visibility = 'visible' if dialogue_manager.state == 'PROVIDED_SHIPMENT_ID' else 'hidden'\n",
        "                follow_up_button2.layout.visibility = 'visible' if dialogue_manager.state in ['RESOLVING', 'CONFIRMING'] else 'hidden'\n",
        "                success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "                if success_rate > 0:\n",
        "                    print(f'Dialogue Success Rate: {success_rate:.2f}')\n",
        "            except Exception as e:\n",
        "                print(f'Error processing query: {e}')\n",
        "\n",
        "    def on_follow_up1_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            response = f'The estimated arrival time for shipment {dialogue_manager.context.get(\"shipment_id\", \"unknown\")} is tomorrow by 3 PM.'\n",
        "            dialogue_manager.history.append(('follow_up', 'Request ETA', response))\n",
        "            print(f'Bot: {response}')\n",
        "            follow_up_button1.layout.visibility = 'hidden'\n",
        "            success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "            if success_rate > 0:\n",
        "                print(f'Dialogue Success Rate: {success_rate:.2f}')\n",
        "\n",
        "    def on_follow_up2_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            if dialogue_manager.state == 'CONFIRMING':\n",
        "                response = f'Confirmed. {dialogue_manager.context.get(\"new_info\", \"action\")} has been updated.'\n",
        "            else:\n",
        "                response = f'Dispute for {dialogue_manager.context.get(\"amount\", \"unknown\")} has been submitted.'\n",
        "            dialogue_manager.history.append(('follow_up', 'Confirm', response))\n",
        "            dialogue_manager.state = 'INITIAL'\n",
        "            print(f'Bot: {response}')\n",
        "            follow_up_button2.layout.visibility = 'hidden'\n",
        "            success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "            if success_rate > 0:\n",
        "                print(f'Dialogue Success Rate: {success_rate:.2f}')\n",
        "\n",
        "    submit_button.on_click(on_submit_clicked)\n",
        "    follow_up_button1.on_click(on_follow_up1_clicked)\n",
        "    follow_up_button2.on_click(on_follow_up2_clicked)\n",
        "\n",
        "    # Display UI\n",
        "    display(widgets.VBox([\n",
        "        widgets.HTML('<h3>Trucking Co. Customer Chatbot</h3>'),\n",
        "        input_box,\n",
        "        submit_button,\n",
        "        follow_up_button1,\n",
        "        follow_up_button2,\n",
        "        output_area\n",
        "    ]))\n",
        "    print('Welcome! You can greet me, chat about your day, or ask about delivery, billing, or Comdata/IFTA services.')\n",
        "    print('Type your query and click Submit.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8",
      "language": "python",
      "name": "python3.8"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}