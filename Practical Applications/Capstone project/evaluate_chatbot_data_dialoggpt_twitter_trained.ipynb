{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHKfnnO9nOlD"
      },
      "source": [
        "# Customer Service Chatbot with DialogGPT for Conversational Intents\n",
        "\n",
        "This Jupyter Notebook updates `evaluate_chatbot_data_dialoggpt_twitter_trained.ipynb` to fix syntax errors and a class mismatch error in model evaluation (5 classes vs. 11 target names). It uses Microsoft’s DialogGPT for conversational intents (greeting, farewell, small_talk, compliment, weather_query) and DistilBERT for trucking-specific intents (delivery_status, billing_issue, account_update, service_inquiry, fuel_card_query, general_query). Trains on Twitter dataset (`tweets.csv` or `trucking_chatbot_test_dataset.csv`) with interactive ipywidgets UI.\n",
        "\n",
        "## Objectives\n",
        "- Inspect Twitter dataset for intents and entities (e.g., location, company).\n",
        "- Train DistilBERT for intent classification.\n",
        "- Fine-tune DialogGPT on conversational Twitter data.\n",
        "- Evaluate DistilBERT with accuracy, F1-score, confusion matrix, and dialogue success rate.\n",
        "- Implement hybrid dialogue management with DialogGPT and DistilBERT.\n",
        "- Provide interactive UI for customer interaction.\n",
        "\n",
        "## Requirements\n",
        "- Python 3.8 (recommended; 3.9 also compatible)\n",
        "- Install: `pip install transformers==4.44.2 torch==2.5.0 pandas==2.2.3 numpy==2.1.1 scikit-learn==1.5.2 datasets==3.0.1 seaborn==0.13.2 matplotlib==3.9.2 ipywidgets==8.1.5`\n",
        "- For GPU: `pip install torch==2.5.0+cu121 --index-url https://download.pytorch.org/whl/cu121`\n",
        "- Place `trucking_chatbot_test_dataset.csv` or `tweets.csv` in the directory.\n",
        "- Enable widgets: `jupyter nbextension enable --py widgetsnbextension`\n",
        "\n",
        "## Notes\n",
        "- Dataset: https://www.kaggle.com/thoughtvector/customer-support-on-twitter\n",
        "- Reflects tariffs/Moody’s downgrade in billing/fuel inquiries.\n",
        "- Professional responses with dynamic DialogGPT conversation.\n",
        "- Date: May 29, 2025, 1:44 PM EDT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3ihl3KAfnOlF",
        "outputId": "28e047cf-5b1b-4cd7-b784-1b96723b9984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.44.2\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting numpy==1.25.0\n",
            "  Downloading numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scikit-learn==1.5.2\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Collecting matplotlib==3.9.2\n",
            "  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting ipywidgets==8.1.5\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.31.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (3.2.3)\n",
            "Collecting comm>=0.1.3 (from ipywidgets==8.1.5)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets==8.1.5)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.5) (3.0.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets==8.1.5)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.5) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.5) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.5) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.1.5) (0.2.13)\n",
            "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, scikit-learn, nvidia-cusolver-cu12, matplotlib, ipywidgets, transformers\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.2\n",
            "    Uninstalling transformers-4.52.2:\n",
            "      Successfully uninstalled transformers-4.52.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.25.0 which is incompatible.\n",
            "blosc2 3.3.3 requires numpy>=1.26, but you have numpy 1.25.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comm-0.2.2 ipywidgets-8.1.5 jedi-0.19.2 matplotlib-3.9.2 numpy-1.25.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 scikit-learn-1.5.2 tokenizers-0.19.1 transformers-4.44.2 widgetsnbextension-4.0.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipywidgets",
                  "numpy",
                  "nvidia",
                  "transformers"
                ]
              },
              "id": "4fc8498d796043f89bc354698e36dad5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformers==4.44.2 torch==2.6.0 pandas==2.2.2 numpy==1.25.0 scikit-learn==1.5.2 datasets seaborn==0.13.2 matplotlib==3.9.2 ipywidgets==8.1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTwn5gfKnOlH",
        "outputId": "0b989990-8ef3-4a9e-cd80-4b57e67d0497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from jaraco.functools) (10.7.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --no-cache-dir --upgrade jaraco.functools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B03F2HrnOlH",
        "outputId": "4c50197c-58dd-40d3-f8a1-4b8d75226192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "pip install --no-cache-dir --upgrade accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoQ3zdCTnOlH"
      },
      "source": [
        "## Step 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "efdeacd788d348df8f477c6e49e9ce00",
            "890bf3fa631347c584d0f1d3c7a60b8b",
            "aff828c8ece74276a45cbe5e64bbfc92",
            "dea6f8befabb40ea80cb3eda8a47dba7",
            "fb0591b5d5d54cf4bed48aa2fa6192c8",
            "b19ec1d0f0ae4b34ac2b453ca92e3477",
            "cc9de17df52c4a91ba51fbf9d5de5637",
            "389823c327094fa0a6c1b44eedd350a4",
            "b86d2921422d45ca8279b12acbefcc52",
            "0efe30fe7ffa4591986810539ffa9d47",
            "f90bba83ad144a5183b5ef9af1792874"
          ]
        },
        "id": "YFIu-KRdnOlH",
        "outputId": "644923fd-adb9-4daf-c216-03044b1686f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efdeacd788d348df8f477c6e49e9ce00"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import Dataset, ClassLabel\n",
        "import torch\n",
        "import json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import re\n",
        "from datetime import datetime\n",
        "import os\n",
        "from matplotlib.pyplot import text\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE-NwBzKnOlI"
      },
      "source": [
        "## Step 2: Inspect and Preprocess Dataset\n",
        "\n",
        "Load Twitter dataset, add conversational examples, label intents/entities. Ensure all intents are preserved.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcHG8R74nOlI",
        "outputId": "59f9cc13-933a-4194-c1a3-1b79730062e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing intents ['service_inquiry'] or low sample counts {'greeting': 967867, 'general_query': 317529, 'account_update': 169897, 'farewell': 122558, 'weather_query': 41960, 'delivery_status': 27721, 'billing_issue': 26406, 'direction': 23030, 'login_issue': 5824, 'compliment': 5476, 'fuel_card_query': 366, 'small_talk': 38}. Adding placeholders.\n",
            "Dataset Shape: (1708677, 9)\n",
            "Columns: ['tweet_id', 'author_id', 'inbound', 'created_at', 'text', 'response_tweet_id', 'in_response_to_tweet_id', 'intent', 'entities']\n",
            "Sample Rows:\n",
            "    tweet_id   author_id inbound                      created_at  \\\n",
            "0       2.0      115712    True  Tue Oct 31 22:11:45 +0000 2017   \n",
            "1       6.0  sprintcare   False  Tue Oct 31 21:46:24 +0000 2017   \n",
            "2       8.0      115712    True  Tue Oct 31 21:45:10 +0000 2017   \n",
            "3      11.0  sprintcare   False  Tue Oct 31 22:10:35 +0000 2017   \n",
            "4      16.0      115713    True  Tue Oct 31 20:00:43 +0000 2017   \n",
            "\n",
            "                                                text response_tweet_id  \\\n",
            "0      @sprintcare and how do you propose we do that               NaN   \n",
            "1  @115712 Can you please send us a private messa...               5,7   \n",
            "2          @sprintcare is the worst customer service            9,6,10   \n",
            "3  @115713 This is saddening to hear. Please shoo...               NaN   \n",
            "4  @sprintcare Since I signed up with you....Sinc...                15   \n",
            "\n",
            "   in_response_to_tweet_id         intent entities  \n",
            "0                      1.0  general_query       []  \n",
            "1                      8.0  general_query       []  \n",
            "2                      NaN  general_query       []  \n",
            "3                     12.0       greeting       []  \n",
            "4                     17.0  general_query       []  \n",
            "Missing Values:\n",
            " tweet_id                        5\n",
            "author_id                       5\n",
            "inbound                         5\n",
            "created_at                      5\n",
            "text                            0\n",
            "response_tweet_id          636177\n",
            "in_response_to_tweet_id    505564\n",
            "intent                          0\n",
            "entities                        0\n",
            "dtype: int64\n",
            "Intent Distribution:\n",
            " intent\n",
            "greeting           967867\n",
            "general_query      317529\n",
            "account_update     169897\n",
            "farewell           122558\n",
            "weather_query       41960\n",
            "delivery_status     27721\n",
            "billing_issue       26406\n",
            "direction           23030\n",
            "login_issue          5824\n",
            "compliment           5476\n",
            "fuel_card_query       366\n",
            "small_talk             38\n",
            "service_inquiry         5\n",
            "Name: count, dtype: int64\n",
            "Unique Intents: ['account_update', 'billing_issue', 'compliment', 'delivery_status', 'direction', 'farewell', 'fuel_card_query', 'general_query', 'greeting', 'login_issue', 'service_inquiry', 'small_talk', 'weather_query']\n",
            "Entity Samples:\n",
            "                                                  text  \\\n",
            "15  Yo @Ask_Spectrum, your customer service reps a...   \n",
            "26  @115722 MD. And this was sent to the wrong add...   \n",
            "62  @115742 I love it! Thanks so much for stopping...   \n",
            "63  @ChipotleTweets name a better halloween duo #s...   \n",
            "73  @115749 As our packaging is sufficient, any ex...   \n",
            "\n",
            "                                         entities  \n",
            "15            [{'entity': 'pin', 'value': 'pin'}]  \n",
            "26    [{'entity': 'address', 'value': 'address'}]  \n",
            "62            [{'entity': 'pin', 'value': 'pin'}]  \n",
            "63  [{'entity': 'location', 'value': 'Speedway'}]  \n",
            "73            [{'entity': 'pin', 'value': 'pin'}]  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def inspect_dataset(file_path='/content/sample_data/twcs.csv'):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print('Dataset not found. Using Twitter dataset.')\n",
        "        try:\n",
        "            df = pd.read_csv('tweets.csv')\n",
        "        except FileNotFoundError:\n",
        "            print('Download from: https://www.kaggle.com/thoughtvector/customer-support-on-twitter')\n",
        "            data = {\n",
        "                'text': [\n",
        "                    'Where is my shipment from Speedway?', 'Why is my Comdata bill so high?',\n",
        "                    'Need to update my address for IFTA', 'What are your hauling rates?',\n",
        "                    'Help with my account', 'Hello', 'How are you', 'How can I help you',\n",
        "                    'Track my cargo', 'Overcharged on Comdata invoice', 'Hi there',\n",
        "                    'Change my contact info', 'Tell me about Comdata services', 'Lost my shipment',\n",
        "                    'Good morning', 'Thanks for your help', 'Bye', 'What’s new?',\n",
        "                    'How’s it going?', 'How’s your day going?', 'Any big plans?',\n",
        "                    'How’s the trucking life?', 'You’re awesome!', 'Great job!',\n",
        "                    'How’s the weather there?', 'Is it raining?',\n",
        "                    'How do I get to Chicago?', 'What’s the best route to Miami?',\n",
        "                    'Directions to the nearest truck stop', 'Can you route me to Denver?',\n",
        "                    'Address is not correct on card', 'Update my billing address',\n",
        "                    'Wrong address on my account', 'Change address for fuel card',\n",
        "                    'My Comdata card is not working', 'Comdata card declined at pump',\n",
        "                    'Fix my Comdata card issue', 'Why isn’t my Comdata card accepted?',\n",
        "                    'I am not able to login to the Driven website', 'Can’t access my account on Driven',\n",
        "                    'Login error on the Driven website', 'Driven website login not working',\n",
        "                    'I want to change my card pin on the Driven website', 'Update my fuel card PIN on Driven',\n",
        "                    'Need to reset my card PIN for Driven', 'Change PIN for my Comdata card on Driven website'\n",
        "                ],\n",
        "                'intent': [\n",
        "                    'delivery_status', 'billing_issue', 'account_update', 'service_inquiry',\n",
        "                    'general_query', 'greeting', 'greeting', 'greeting', 'delivery_status',\n",
        "                    'billing_issue', 'greeting', 'account_update', 'fuel_card_query',\n",
        "                    'general_query', 'greeting', 'farewell', 'farewell', 'small_talk',\n",
        "                    'small_talk', 'small_talk', 'small_talk', 'small_talk', 'compliment',\n",
        "                    'compliment', 'weather_query', 'weather_query',\n",
        "                    'direction', 'direction', 'direction', 'direction',\n",
        "                    'account_update', 'account_update', 'account_update', 'account_update',\n",
        "                    'fuel_card_query', 'fuel_card_query', 'fuel_card_query', 'fuel_card_query',\n",
        "                    'login_issue', 'login_issue', 'login_issue', 'login_issue',\n",
        "                    'account_update', 'account_update', 'account_update', 'account_update'\n",
        "                ]\n",
        "            }\n",
        "            df = pd.DataFrame(data)\n",
        "\n",
        "    # Define expected intents\n",
        "    expected_intents = ['delivery_status', 'billing_issue', 'account_update', 'service_inquiry',\n",
        "                        'fuel_card_query', 'general_query', 'greeting', 'farewell',\n",
        "                        'small_talk', 'compliment', 'weather_query', 'direction', 'login_issue']\n",
        "\n",
        "    # Check for null values\n",
        "    if 'text' in df.columns:\n",
        "        df = df.dropna(subset=['text'])\n",
        "    if 'intent' in df.columns:\n",
        "        df = df.dropna(subset=['intent'])\n",
        "\n",
        "    keywords = ['delivery', 'shipment', 'cargo', 'bill', 'invoice', 'payment', 'account',\n",
        "                'service', 'hauling', 'truck', 'comdata', 'ifta', 'speedway', 'fuel',\n",
        "                'tax', 'station', 'hello', 'hi', 'how', 'good', 'bye', 'thanks', 'new',\n",
        "                'day', 'plans', 'awesome', 'great', 'weather', 'rain', 'direction',\n",
        "                'route', 'get to', 'truck stop', 'address', 'card', 'login', 'website', 'portal', 'pin', 'driven']\n",
        "    if 'text' in df.columns:\n",
        "        df = df[df['text'].str.contains('|'.join(keywords), case=False, na=False)]\n",
        "\n",
        "    if 'intent' not in df.columns:\n",
        "        def label_intent(text):\n",
        "            text = text.lower()\n",
        "            if any(word in text for word in ['pin', 'change pin', 'reset pin', 'card pin']):\n",
        "                return 'account_update'\n",
        "            elif any(word in text for word in ['login', 'access account', 'website login', 'portal', 'login error']):\n",
        "                return 'login_issue'\n",
        "            elif any(word in text for word in ['comdata', 'fuel card', 'card declined', 'card not working', 'card issue']):\n",
        "                return 'fuel_card_query'\n",
        "            elif any(word in text for word in ['address', 'update address', 'wrong address', 'billing address', 'card address']):\n",
        "                return 'account_update'\n",
        "            elif any(word in text for word in ['direction', 'route', 'get to', 'truck stop']):\n",
        "                return 'direction'\n",
        "            elif any(word in text for word in ['hello', 'hi', 'how are you', 'how can i help', 'good morning', 'good afternoon']):\n",
        "                return 'greeting'\n",
        "            elif any(word in text for word in ['goodbye', 'bye', 'thanks', 'thank you']):\n",
        "                return 'farewell'\n",
        "            elif any(word in text for word in ['what’s new', 'how’s it going', 'how’s your day', 'any big plans', 'trucking life']):\n",
        "                return 'small_talk'\n",
        "            elif any(word in text for word in ['awesome', 'great job', 'you rock']):\n",
        "                return 'compliment'\n",
        "            elif any(word in text for word in ['weather', 'rain', 'sunny']):\n",
        "                return 'weather_query'\n",
        "            elif any(word in text for word in ['delivery', 'shipment', 'track', 'cargo']):\n",
        "                return 'delivery_status'\n",
        "            elif any(word in text for word in ['bill', 'invoice', 'payment', 'charge']):\n",
        "                return 'billing_issue'\n",
        "            elif any(word in text for word in ['update', 'change', 'contact']) and 'address' not in text:\n",
        "                return 'account_update'\n",
        "            else:\n",
        "                return 'general_query'\n",
        "        df['intent'] = df['text'].apply(label_intent)\n",
        "\n",
        "    def extract_entities(text):\n",
        "        entities = []\n",
        "        text = text.lower()\n",
        "        if 'speedway' in text:\n",
        "            entities.append({'entity': 'location', 'value': 'Speedway'})\n",
        "        if 'comdata' in text:\n",
        "            entities.append({'entity': 'company', 'value': 'Comdata'})\n",
        "        if 'ifta' in text:\n",
        "            entities.append({'entity': 'regulation', 'value': 'IFTA'})\n",
        "        if any(word in text for word in ['chicago', 'miami', 'denver', 'dallas', 'atlanta', 'phoenix']):\n",
        "            entities.append({'entity': 'destination', 'value': text.split()[-1].capitalize()})\n",
        "        if 'address' in text:\n",
        "            entities.append({'entity': 'address', 'value': 'address'})\n",
        "        if 'login' in text or 'website' in text:\n",
        "            entities.append({'entity': 'login', 'value': 'login'})\n",
        "        if 'pin' in text:\n",
        "            entities.append({'entity': 'pin', 'value': 'pin'})\n",
        "        if 'driven' in text:\n",
        "            entities.append({'entity': 'website', 'value': 'Driven'})\n",
        "        return entities\n",
        "\n",
        "    df['entities'] = df['text'].apply(extract_entities)\n",
        "\n",
        "    # Ensure all intents and sufficient samples\n",
        "    intent_counts = df['intent'].value_counts()\n",
        "    missing_intents = [intent for intent in expected_intents if intent not in df['intent'].unique()]\n",
        "    if missing_intents or any(intent_counts.get(intent, 0) < 5 for intent in expected_intents):\n",
        "        print(f'Warning: Missing intents {missing_intents} or low sample counts {intent_counts.to_dict()}. Adding placeholders.')\n",
        "        placeholder_data = []\n",
        "        for intent in expected_intents:\n",
        "            current_count = intent_counts.get(intent, 0)\n",
        "            if current_count < 5:\n",
        "                for _ in range(5 - current_count):\n",
        "                    if intent == 'account_update':\n",
        "                        placeholder_data.append({'text': f'{random.choice([\"Update my\", \"Change my\", \"Reset my\"])} {random.choice([\"address\", \"billing address\", \"card pin\"])} on {random.choice([\"Driven website\", \"Driven\"])}', 'intent': 'account_update', 'entities': [{'entity': 'address', 'value': 'address'}] if 'address' in random.choice([\"address\", \"billing address\"]) else [{'entity': 'pin', 'value': 'pin'}, {'entity': 'website', 'value': 'Driven'}]})\n",
        "                    elif intent == 'login_issue':\n",
        "                        placeholder_data.append({'text': f'{random.choice([\"Can’t login to\", \"Unable to access\", \"Problem logging into\"])} the Driven {random.choice([\"website\", \"portal\"])}', 'intent': 'login_issue', 'entities': [{'entity': 'login', 'value': 'login'}, {'entity': 'website', 'value': 'Driven'}]})\n",
        "                    elif intent == 'fuel_card_query':\n",
        "                        placeholder_data.append({'text': f'My {random.choice([\"Comdata card\", \"fuel card\"])} {random.choice([\"is not working\", \"was declined\", \"has an issue\"])}', 'intent': 'fuel_card_query', 'entities': [{'entity': 'company', 'value': 'Comdata'}]})\n",
        "                    elif intent == 'direction':\n",
        "                        placeholder_data.append({'text': f'How do I get to {random.choice([\"Dallas\", \"Atlanta\", \"Phoenix\"])}?', 'intent': 'direction', 'entities': [{'entity': 'destination', 'value': random.choice([\"Dallas\", \"Atlanta\", \"Phoenix\"])}]})\n",
        "                    elif intent == 'compliment':\n",
        "                        placeholder_data.append({'text': f'You guys are {random.choice([\"great\", \"awesome\", \"fantastic\"])}!', 'intent': 'compliment', 'entities': []})\n",
        "                    elif intent == 'weather_query':\n",
        "                        placeholder_data.append({'text': f'Is it {random.choice([\"raining\", \"sunny\", \"snowing\"])} on my route?', 'intent': 'weather_query', 'entities': []})\n",
        "                    elif intent == 'farewell':\n",
        "                        placeholder_data.append({'text': f'{random.choice([\"Thanks, bye\", \"Goodbye\", \"See ya\"])}!', 'intent': 'farewell', 'entities': []})\n",
        "                    elif intent == 'small_talk':\n",
        "                        placeholder_data.append({'text': f'{random.choice([\"How’s the day going?\", \"What’s new with you?\", \"How’s trucking?\"])}', 'intent': 'small_talk', 'entities': []})\n",
        "                    elif intent == 'greeting':\n",
        "                        placeholder_data.append({'text': f'{random.choice([\"Hello\", \"Hi\", \"Good morning\"])}!', 'intent': 'greeting', 'entities': []})\n",
        "                    elif intent == 'delivery_status':\n",
        "                        placeholder_data.append({'text': f'Track my shipment {random.randint(100, 999)}', 'intent': 'delivery_status', 'entities': []})\n",
        "                    elif intent == 'billing_issue':\n",
        "                        placeholder_data.append({'text': f'Why is my bill ${random.randint(100, 1000)}?', 'intent': 'billing_issue', 'entities': []})\n",
        "                    elif intent == 'service_inquiry':\n",
        "                        placeholder_data.append({'text': f'What are your {random.choice([\"rates\", \"services\", \"routes\"])}?', 'intent': 'service_inquiry', 'entities': []})\n",
        "                    elif intent == 'general_query':\n",
        "                        placeholder_data.append({'text': f'Need help with {random.choice([\"something\", \"my account\", \"a question\"])}', 'intent': 'general_query', 'entities': []})\n",
        "        if placeholder_data:\n",
        "            df = pd.concat([df, pd.DataFrame(placeholder_data)], ignore_index=True)\n",
        "\n",
        "    print('Dataset Shape:', df.shape)\n",
        "    print('Columns:', df.columns.tolist())\n",
        "    print('Sample Rows:\\n', df.head())\n",
        "    print('Missing Values:\\n', df.isnull().sum())\n",
        "    print('Intent Distribution:\\n', df['intent'].value_counts())\n",
        "    print('Unique Intents:', sorted(df['intent'].unique()))\n",
        "    print('Entity Samples:\\n', df[df['entities'].apply(len) > 0][['text', 'entities']].head())\n",
        "    return df, expected_intents\n",
        "\n",
        "df, expected_intents = inspect_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJPxPFk7nOlI"
      },
      "source": [
        "## Step 3: Prepare DialogGPT Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZPaIlQ8nOlI",
        "outputId": "ecad770a-1810-4fc1-d984-40895ec55c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversational Intent Distribution:\n",
            "greeting: 967867\n",
            "farewell: 122558\n",
            "small_talk: 38\n",
            "compliment: 5476\n",
            "weather_query: 41960\n",
            "DialogGPT training data prepared: 1137899 dialogue pairs.\n",
            "Train dataset size: 910319, Eval dataset size: 227580\n"
          ]
        }
      ],
      "source": [
        "def prepare_dialoggpt_training_data(df):\n",
        "    conversational_intents = ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "    df_conversational = df[df['intent'].isin(conversational_intents)][['text', 'intent']]\n",
        "\n",
        "    # Validate dataset\n",
        "    if df_conversational.empty:\n",
        "        raise ValueError(\"No conversational intents found in dataset. Check Cell 2 output.\")\n",
        "\n",
        "    # Check intent distribution\n",
        "    intent_counts = df_conversational['intent'].value_counts()\n",
        "    print('Conversational Intent Distribution:')\n",
        "    for intent in conversational_intents:\n",
        "        count = intent_counts.get(intent, 0)\n",
        "        print(f'{intent}: {count}')\n",
        "        if count < 5:\n",
        "            raise ValueError(f\"Intent {intent} has {count} samples (<5). Add more samples in Cell 2.\")\n",
        "\n",
        "    response_map = {\n",
        "        'greeting': [\n",
        "            'Hello! How can I assist you with your trucking needs today?',\n",
        "            'Hi there! Ready to help with your shipments or account!',\n",
        "            'Good to hear from you! What’s up?'\n",
        "        ],\n",
        "        'farewell': [\n",
        "            'Goodbye! Stay safe on the road.',\n",
        "            'Thanks for connecting!'\n",
        "        ],\n",
        "        'small_talk': [\n",
        "            'My day’s going smoothly, thanks! How’s yours?',\n",
        "            'Trucking life’s always moving! How’s it like for you?',\n",
        "            'Just keeping the wheels turning! Got any big plans?',\n",
        "            'All’s good here! What’s new with you?'\n",
        "        ],\n",
        "        'compliment': [\n",
        "            'Thanks, you’re awesome too! Need help with anything?',\n",
        "            'Appreciate that! What can I do for you today?'\n",
        "        ],\n",
        "        'weather_query': [\n",
        "            'Can’t see the skies, but I can check your route! Where are you headed?',\n",
        "            'Weather’s a mystery here, but I’m ready to help! What’s your destination?'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    dialogues = []\n",
        "    for _, row in df_conversational.iterrows():\n",
        "        user_input = row['text']\n",
        "        intent = row['intent']\n",
        "        response = random.choice(response_map[intent])\n",
        "        dialogues.append({'input': user_input, 'response': response})\n",
        "\n",
        "    dialogue_df = pd.DataFrame(dialogues)\n",
        "    dataset = Dataset.from_pandas(dialogue_df)\n",
        "\n",
        "    # Manual train/eval split (80/20)\n",
        "    indices = list(range(len(dataset)))\n",
        "    random.shuffle(indices)\n",
        "    split_idx = int(0.8 * len(indices))\n",
        "    train_indices = indices[:split_idx]\n",
        "    eval_indices = indices[split_idx:]\n",
        "    train_dataset = dataset.select(train_indices)\n",
        "    eval_dataset = dataset.select(eval_indices)\n",
        "\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    dialogue_df.to_csv('data/dialoggpt_dialogues.csv', index=False)\n",
        "\n",
        "    print(f'DialogGPT training data prepared: {len(dialogue_df)} dialogue pairs.')\n",
        "    print(f'Train dataset size: {len(train_dataset)}, Eval dataset size: {len(eval_dataset)}')\n",
        "    return train_dataset, eval_dataset\n",
        "\n",
        "dialoggpt_train_dataset, dialoggpt_eval_dataset = prepare_dialoggpt_training_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYSNfL3EnOlJ"
      },
      "source": [
        "## Step 4: Fine-Tune DialogGPT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9vS5kWZCnOlJ",
        "outputId": "c6e8512c-2bd8-449c-eed4-d9ca61303377"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dialoggpt_train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-72ba82d60a28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mdialoggpt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialoggpt_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tune_dialoggpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialoggpt_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialoggpt_eval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_fine_tune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdialoggpt_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using pretrained DialogGPT due to fine-tuning error.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dialoggpt_train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "from ast import Not\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def load_saved_model(model_path='./dialoggpt_model'):\n",
        "    \"\"\"Load a saved DialogGPT model and tokenizer.\"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"No saved model found at {model_path}. Using pretrained model.\")\n",
        "            return None, None\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        print(f\"Loaded model and tokenizer from {model_path}.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading saved model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def fine_tune_dialoggpt(train_dataset, eval_dataset, force_fine_tune=False):\n",
        "    if not force_fine_tune:\n",
        "      # Try loading saved model first\n",
        "      model, tokenizer = load_saved_model()\n",
        "      if model is not None and tokenizer is not None:\n",
        "          return model, tokenizer\n",
        "\n",
        "    # If no saved model, proceed with fine-tuning\n",
        "    model_name = 'microsoft/DialoGPT-medium'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    def preprocess_dialogues(example):\n",
        "        try:\n",
        "            conversation = f\"{example['input']} {tokenizer.eos_token} {example['response']}\"\n",
        "            tokenized = tokenizer(\n",
        "                conversation,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            result = {\n",
        "                'input_ids': tokenized['input_ids'].squeeze(0),\n",
        "                'attention_mask': tokenized['attention_mask'].squeeze(0),\n",
        "                'labels': tokenized['input_ids'].squeeze(0).clone()\n",
        "            }\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f'Error in preprocess_dialogues: {e}')\n",
        "            raise\n",
        "\n",
        "    try:\n",
        "        tokenized_train_dataset = train_dataset.map(\n",
        "            preprocess_dialogues,\n",
        "            remove_columns=['input', 'response'],\n",
        "            desc=\"Tokenizing train dataset\",\n",
        "            #disable_progress_bar=True\n",
        "        )\n",
        "        tokenized_eval_dataset = eval_dataset.map(\n",
        "            preprocess_dialogues,\n",
        "            remove_columns=['input', 'response'],\n",
        "            desc=\"Tokenizing eval dataset\",\n",
        "            #disable_progress_bar=True\n",
        "        )\n",
        "        tokenized_train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "        tokenized_eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "    except Exception as e:\n",
        "        print(f'Error tokenizing dataset: {e}')\n",
        "        return None, None\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./dialoggpt_results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=3,\n",
        "        per_device_eval_batch_size=3,\n",
        "        warmup_steps=10,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./dialoggpt_logs',\n",
        "        logging_steps=20,\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=0\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset,\n",
        "        eval_dataset=tokenized_eval_dataset\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        trainer.train()\n",
        "        trainer.save_model('./dialoggpt_model')\n",
        "        tokenizer.save_pretrained('./dialoggpt_model')\n",
        "        print('DialogGPT model fine-tuned and saved.')\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f'Error fine-tuning DialogGPT: {e}')\n",
        "        print('Falling back to pretrained DialogGPT model.')\n",
        "        return None, None\n",
        "\n",
        "dialoggpt_model, dialoggpt_tokenizer = fine_tune_dialoggpt(dialoggpt_train_dataset, dialoggpt_eval_dataset,force_fine_tune=True)\n",
        "if dialoggpt_model is None:\n",
        "    print('Using pretrained DialogGPT due to fine-tuning error.')\n",
        "    dialoggpt_model = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-medium')\n",
        "    dialoggpt_tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')\n",
        "    dialoggpt_tokenizer.pad_token = dialoggpt_tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 5: Test Inference: To test the loaded model for inference"
      ],
      "metadata": {
        "id": "c316m4Qsn9lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(input_text, model, tokenizer, max_length=50):\n",
        "    inputs = tokenizer(input_text + tokenizer.eos_token, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = inputs['input_ids'].to(model.device)\n",
        "    attention_mask = inputs['attention_mask'].to(model.device)\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "    return response.split(tokenizer.eos_token)[-2].strip()\n",
        "\n",
        "# Test the model\n",
        "test_inputs = [\"Hello!\", \"How’s the weather there?\", \"You’re awesome!\"]\n",
        "for input_text in test_inputs:\n",
        "    response = generate_response(input_text, dialoggpt_model, dialoggpt_tokenizer)\n",
        "    print(f\"Input: {input_text}\\nResponse: {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naWsmA2-n6JP",
        "outputId": "b7b0284b-d9c5-4e6b-8a26-548fc3f2334d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Hello!\n",
            "Response: Hello! How can I assist you with your trucking needs today?\n",
            "\n",
            "Input: How’s the weather there?\n",
            "Response: Can’t see the skies, but I can check your route! Where are you headed?\n",
            "\n",
            "Input: You’re awesome!\n",
            "Response: Appreciate that! What can I do for you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeyRlcf_nOlJ"
      },
      "source": [
        "## Step 5: Preprocess for DistilBERT\n",
        "\n",
        "Ensure all intents are included in the tokenized dataset and label_map.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471,
          "referenced_widgets": [
            "3bc6238ff5644a68b2c99a6d13b2f83b",
            "78bcd896921f4dbda67fdbb2f3fd481a",
            "6b0edbee0350464bbe7d49829f06dadb",
            "d1451290fe2e40b483e6517a6fe98e1a",
            "4baf2ad3775d47f49e5edd7fc309d3ac",
            "f7bbc76b03a24a688d1e31fb9686234a",
            "057b930029564e73bb3a7a20733192cc",
            "e57a08b704464f1cafc2b9d2d3b825da",
            "5db0c26c3fbf46fe990b59ddff41dc95",
            "0e90f41d09be48b9a99a10293f3ed95a",
            "da47c2c60b76463bb4fd768c174d37ea",
            "7d2ee64fbb654e9e9aaae77a9add2444",
            "f4f549c1af174ef3954314a2153cfa01",
            "024aba354d904ef4b0ff565aba89ae8e",
            "ed49733ab230441fa3c938d6866d5959",
            "e1e243b1604f431f8a90244a538e3575",
            "88a388a014dc46af967ea38c1d3f0aef",
            "9d4d3c3c66da48b08bde87d61d7f7dc0",
            "ae5e7a08e7d644c9a7d20a16b40ad2a8",
            "07494715f43e499b8e13ad733a4ff010",
            "42fc1ad419b04b8a9bd465f52c41288a",
            "13b9955d8f9e4be49626addaaaeae1e5",
            "72e4efaec021457db95edbd28ba04aab",
            "92baa557a15347409a517868bbf14ba8",
            "32e37f49da754972a06dd3e2bed47198",
            "246775e809a342a19fb307fa0fc1ba11",
            "75cf6144bbc041a3a3c675838eaaa00e",
            "f38847f9cbf64b3d99f485c634e91a25",
            "3ad526c6fb3a410cae3f3e8a124eefba",
            "154a58d0802844b5beebd01ee18c3019",
            "bce89bcc0688410aacb0b46f33082fa6",
            "4727cb7891a247f79a13bb83109bee15",
            "7ce6075dbc92445784850d8be543fbee"
          ]
        },
        "id": "iYF2tkasnOlK",
        "outputId": "2f535704-d390-4dce-ba0d-cb8b5cb2e865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution in Dataset (Label ID: Count):\n",
            "greeting (8): 967867\n",
            "general_query (7): 317529\n",
            "account_update (0): 169897\n",
            "farewell (5): 122558\n",
            "weather_query (12): 41960\n",
            "delivery_status (3): 27721\n",
            "billing_issue (1): 26406\n",
            "direction (4): 23030\n",
            "login_issue (9): 5824\n",
            "compliment (2): 5476\n",
            "fuel_card_query (6): 366\n",
            "small_talk (11): 38\n",
            "service_inquiry (10): 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1708677 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bc6238ff5644a68b2c99a6d13b2f83b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1708677 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d2ee64fbb654e9e9aaae77a9add2444"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1708677 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72e4efaec021457db95edbd28ba04aab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Features:\n",
            " {'text': Value(dtype='string', id=None), 'labels': ClassLabel(names=['account_update', 'billing_issue', 'compliment', 'delivery_status', 'direction', 'farewell', 'fuel_card_query', 'general_query', 'greeting', 'login_issue', 'service_inquiry', 'small_talk', 'weather_query'], id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n",
            "Label Map: {'account_update': 0, 'billing_issue': 1, 'compliment': 2, 'delivery_status': 3, 'direction': 4, 'farewell': 5, 'fuel_card_query': 6, 'general_query': 7, 'greeting': 8, 'login_issue': 9, 'service_inquiry': 10, 'small_talk': 11, 'weather_query': 12}\n"
          ]
        }
      ],
      "source": [
        "def preprocess_data(df):\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "    # Create label_map with all expected intents\n",
        "    #expected_intents = ['delivery_status', 'billing_issue', 'account_update', 'service_inquiry', 'fuel_card_query',\n",
        "                       # 'general_query', 'greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "    label_map = {label: idx for idx, label in enumerate(sorted(expected_intents))}\n",
        "\n",
        "    # Verify 'intent' column exists\n",
        "    if 'intent' not in df.columns:\n",
        "        raise ValueError(\"'intent' column missing in DataFrame. Check Cell 2 output.\")\n",
        "\n",
        "    # Filter dataset to include only expected intents\n",
        "    df_filtered = df[df['intent'].isin(expected_intents)][['text', 'intent']].copy()\n",
        "\n",
        "    # Check for empty dataset\n",
        "    if df_filtered.empty:\n",
        "        raise ValueError(\"Filtered dataset is empty. Check Cell 2 filtering or intent distribution.\")\n",
        "\n",
        "    # Check for missing intents and warn\n",
        "    present_intents = df_filtered['intent'].unique()\n",
        "    missing_intents = [intent for intent in expected_intents if intent not in present_intents]\n",
        "    if missing_intents:\n",
        "        print(f'Warning: Intents {missing_intents} missing in dataset after filtering.')\n",
        "\n",
        "    dataset = Dataset.from_pandas(df_filtered)\n",
        "\n",
        "    # Validate dataset size\n",
        "    if len(dataset) == 0:\n",
        "        raise ValueError(\"Dataset is empty after conversion. Check Cell 2 output.\")\n",
        "\n",
        "    # Compute label distribution\n",
        "    label_counts = pd.Series([label_map.get(x['intent'], -1) for x in dataset]).value_counts()\n",
        "    print('Label Distribution in Dataset (Label ID: Count):')\n",
        "    for label_id, count in label_counts.items():\n",
        "        if label_id == -1:\n",
        "            print(f'Invalid Labels: {count}')\n",
        "        else:\n",
        "            intent = list(label_map.keys())[list(label_map.values()).index(label_id)]\n",
        "            print(f'{intent} ({label_id}): {count}')\n",
        "\n",
        "    # Check for invalid or insufficient labels\n",
        "    if -1 in label_counts:\n",
        "        raise ValueError(f\"Invalid intents found: {label_counts[-1]} samples not in {expected_intents}.\")\n",
        "    min_samples = 5\n",
        "    low_sample_labels = {label_id: count for label_id, count in label_counts.items() if count < min_samples and label_id != -1}\n",
        "    if low_sample_labels:\n",
        "        low_intents = {list(label_map.keys())[list(label_map.values()).index(k)]: v for k, v in low_sample_labels.items()}\n",
        "        raise ValueError(f\"Intents with < {min_samples} samples: {low_intents}. Add more samples in Cell 2.\")\n",
        "\n",
        "    # Tokenize and rename 'intent' to 'labels'\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_dataset = tokenized_dataset.rename_column('intent', 'labels')\n",
        "    tokenized_dataset = tokenized_dataset.map(lambda x: {'labels': label_map[x['labels']]})\n",
        "    tokenized_dataset = tokenized_dataset.cast_column('labels', ClassLabel(names=list(label_map.keys())))\n",
        "\n",
        "    # Verify dataset features\n",
        "    print('Dataset Features:\\n', tokenized_dataset.features)\n",
        "    return tokenized_dataset, label_map, tokenizer\n",
        "\n",
        "dataset, label_map, tokenizer = preprocess_data(df)\n",
        "print(f'Label Map: {label_map}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbhb9SfnOlK"
      },
      "source": [
        "## Step 6: Train DistilBERT Model\n",
        "\n",
        "Ensure model is trained with correct number of labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427,
          "referenced_widgets": [
            "9318e8820e4b4e2c8ea7202b179ceeb5",
            "999196219815413685763472e6142ad5",
            "64e2ea72504e42829c6697e51ff5eae0",
            "baa3aed738384c67bf2dbde204c6f26e",
            "06f97a5ad0784795acc858a351b435b9",
            "5a82bf9ae2ba4335bdba96575214a9ae",
            "fd1baa05fef24febb784339a6edc16e6",
            "8f4abb7efef0425d96e44e818f36fea9",
            "3f375c5a4a2f4ecea463b06ce4822189",
            "5cf78895ad3d4d868563becb609d5ece",
            "672406c9723c4ac0814b1571118b970b",
            "8c7939a5ce554852937ae41ba17d3fdb",
            "82f3f63797de42438059a5ea28850dfe",
            "eb3e5ca263884f8e87d8139250f80193",
            "d4c07da591bc4dadb8eb384880dffd8d",
            "182a6ee8f1ad4ab4abb37eb5adff5a8c",
            "bbc6f67f0a5245c3976247d57f72bfd2",
            "728dd2107c4b46899d57701822c6b05c",
            "2b7247948e504b6b88a0c98b55e1297b",
            "5080e5222a9c40c28b9b78a7196d7c83",
            "fd8e0585d537436a88183932a289c986",
            "f20298ab858b4ccab927b6c093555add"
          ]
        },
        "id": "LhY-c2XLnOlK",
        "outputId": "5bfa9be6-ac39-4637-d47d-245d2ca7e7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forcing fine-tuning, skipping model loading.\n",
            "Train dataset size: 1366941, Eval dataset size: 341736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing DistilBERT model. Note: Classifier weights are newly initialized, which is normal for fine-tuning.\n",
            "Tokenizing train dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/1366941 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9318e8820e4b4e2c8ea7202b179ceeb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing eval dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing eval dataset:   0%|          | 0/341736 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c7939a5ce554852937ae41ba17d3fdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete.\n",
            "Starting fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnisheeth_g2000\u001b[0m (\u001b[33mnisheeth_g2000-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250602_151741-gh40yn9q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nisheeth_g2000-self/huggingface/runs/gh40yn9q' target=\"_blank\">./distilbert_results</a></strong> to <a href='https://wandb.ai/nisheeth_g2000-self/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nisheeth_g2000-self/huggingface' target=\"_blank\">https://wandb.ai/nisheeth_g2000-self/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nisheeth_g2000-self/huggingface/runs/gh40yn9q' target=\"_blank\">https://wandb.ai/nisheeth_g2000-self/huggingface/runs/gh40yn9q</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='170869' max='512604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [170867/512604 1:29:48 < 2:59:36, 31.71 it/s, Epoch 1.00/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3043' max='42717' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3043/42717 00:29 < 06:28, 102.24 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
        "from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def load_saved_distilbert(model_path='./chatbot_model'):\n",
        "    \"\"\"Load a saved DistilBERT model and tokenizer.\"\"\"\n",
        "    print(f\"Checking for saved model at {model_path}\")\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Directory {model_path} does not exist.\")\n",
        "        return None, None\n",
        "    print(f\"Files in {model_path}: {os.listdir(model_path)}\")\n",
        "\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load tokenizer from {model_path}: {e}. Using pretrained tokenizer.\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "        print(f\"Loaded DistilBERT model and tokenizer from {model_path} on {device}.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading saved DistilBERT model: {e}. Proceeding with fine-tuning.\")\n",
        "        return None, None\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy for evaluation.\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "def train_distilbert(df, force_fine_tune=False):\n",
        "    distilbert_model=distilbert_tokenizer=None\n",
        "    # Try loading saved model unless forced to fine-tune\n",
        "    if not force_fine_tune:\n",
        "        distilbert_model, distilbert_tokenizer = load_saved_distilbert()\n",
        "        #if distilbert_model is not None and distilbert_tokenizer is not None:\n",
        "            #return distilbert_model, distilbert_tokenizer, None, None, None, None\n",
        "    else:\n",
        "        print(\"Forcing fine-tuning, skipping model loading.\")\n",
        "\n",
        "    # Prepare dataset\n",
        "    unique_labels = expected_intents #['delivery_status', 'billing_issue', 'account_update', 'service_inquiry','fuel_card_query', 'general_query', 'greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "    le = LabelEncoder()\n",
        "    le.fit(unique_labels)\n",
        "    df['label'] = le.transform(df['intent'])\n",
        "    label_map = dict(zip(unique_labels, range(len(unique_labels))))\n",
        "\n",
        "    dataset = Dataset.from_pandas(df[['text', 'label']])\n",
        "    indices = list(range(len(dataset)))\n",
        "    random.shuffle(indices)\n",
        "    split_idx = int(0.8 * len(indices))\n",
        "    train_indices = indices[:split_idx]\n",
        "    eval_indices = indices[split_idx:]\n",
        "    train_dataset = dataset.select(train_indices)\n",
        "    eval_dataset = dataset.select(eval_indices)\n",
        "    print(f\"Train dataset size: {len(train_dataset)}, Eval dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "     # Initialize model and tokenizer\n",
        "    model_name = 'distilbert-base-uncased'\n",
        "    if distilbert_model is not None and distilbert_tokenizer is not None:\n",
        "        model = distilbert_model\n",
        "        tokenizer = distilbert_tokenizer\n",
        "    else:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(unique_labels))\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    print(\"Initializing DistilBERT model. Note: Classifier weights are newly initialized, which is normal for fine-tuning.\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    def tokenize_function(example):\n",
        "        try:\n",
        "            tokenized = tokenizer(\n",
        "                example['text'],\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                return_tensors='pt',\n",
        "            )\n",
        "            return {\n",
        "                'input_ids': tokenized['input_ids'].squeeze(0),\n",
        "                'attention_mask': tokenized['attention_mask'].squeeze(0),\n",
        "                'labels': torch.tensor(example['label'], dtype=torch.long).to(device)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f'Error in tokenize_function: {e}')\n",
        "            raise\n",
        "\n",
        "    try:\n",
        "        print(\"Tokenizing train dataset...\")\n",
        "        tokenized_train_dataset = train_dataset.map(\n",
        "            tokenize_function,\n",
        "            remove_columns=['text', 'label'],\n",
        "            desc=\"Tokenizing train dataset\"\n",
        "        )\n",
        "        print(\"Tokenizing eval dataset...\")\n",
        "        tokenized_eval_dataset = eval_dataset.map(\n",
        "            tokenize_function,\n",
        "            remove_columns=['text', 'label'],\n",
        "            desc=\"Tokenizing eval dataset\"\n",
        "        )\n",
        "        tokenized_train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "        tokenized_eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "        print(\"Tokenization complete.\")\n",
        "    except Exception as e:\n",
        "        print(f'Error tokenizing dataset: {e}')\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./distilbert_results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=10,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./distilbert_logs',\n",
        "        logging_steps=10,\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=0\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset,\n",
        "        eval_dataset=tokenized_eval_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        if force_fine_tune:\n",
        "          print(\"Starting fine-tuning...\")\n",
        "          trainer.train()\n",
        "          print(\"Evaluating model during training...\")\n",
        "          eval_results = trainer.evaluate()\n",
        "          print(f\"Training evaluation results: {eval_results}\")\n",
        "          os.makedirs('./chatbot_model', exist_ok=True)\n",
        "          print(\"Saving model...\")\n",
        "          trainer.save_model('./chatbot_model')\n",
        "          print(\"Saving tokenizer...\")\n",
        "          tokenizer.save_pretrained('./chatbot_model')\n",
        "          print(\"Saving unique labels...\")\n",
        "          with open(os.path.join('./chatbot_model', 'labels.json'), 'w') as f:\n",
        "              json.dump(unique_labels, f)\n",
        "          print(\"Saving label map...\")\n",
        "          with open(os.path.join('./chatbot_model', 'label_map.json'), 'w') as f:\n",
        "              json.dump(label_map, f)\n",
        "          print('DistilBERT model fine-tuned and saved to ./chatbot_model.')\n",
        "          print(f\"Files saved in ./chatbot_model: {os.listdir('./chatbot_model')}\")\n",
        "        else:\n",
        "          print(\"Skipping fine-tuning.\")\n",
        "        return model, tokenizer, trainer, tokenized_eval_dataset, label_map, unique_labels\n",
        "    except Exception as e:\n",
        "        print(f'Error fine-tuning or saving DistilBERT: {e}')\n",
        "        try:\n",
        "            tokenizer.save_pretrained('./chatbot_model')\n",
        "            print(\"Manually saved tokenizer to ./chatbot_model.\")\n",
        "            print(\"Saving unique labels...\")\n",
        "            with open(os.path.join('./chatbot_model', 'labels.json'), 'w') as f:\n",
        "              json.dump(unique_labels, f)\n",
        "            print(\"Saving label map...\")\n",
        "            with open(os.path.join('./chatbot_model', 'label_map.json'), 'w') as f:\n",
        "              json.dump(label_map, f)\n",
        "            print(f\"Files in ./chatbot_model: {os.listdir('./chatbot_model')}\")\n",
        "        except Exception as save_e:\n",
        "            print(f\"Failed to save tokenizer or labels: {save_e}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "# Force fine-tuning to generate tokenizer files\n",
        "distilbert_model, distilbert_tokenizer, distilbert_trainer, eval_dataset, label_map, unique_labels = train_distilbert(df, force_fine_tune=True)\n",
        "if distilbert_model is None:\n",
        "    print('Using pretrained DistilBERT due to fine-tuning/loading error.')\n",
        "    distilbert_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=11)\n",
        "    distilbert_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    distilbert_model.to(device)\n",
        "    distilbert_trainer = None\n",
        "    eval_dataset = None\n",
        "    label_map = None\n",
        "    unique_labels = ['delivery_status', 'billing_issue', 'account_update', 'service_inquiry',\n",
        "                     'fuel_card_query', 'general_query', 'greeting', 'farewell',\n",
        "                     'small_talk', 'compliment', 'weather_query']\n",
        "    try:\n",
        "        distilbert_tokenizer.save_pretrained('./chatbot_model')\n",
        "        with open(os.path.join('./chatbot_model', 'labels.json'), 'w') as f:\n",
        "            json.dump(unique_labels, f)\n",
        "        print(\"Saved pretrained tokenizer and unique labels to ./chatbot_model.\")\n",
        "        print(f\"Files in ./chatbot_model: {os.listdir('./chatbot_model')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to save pretrained tokenizer or labels: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 5: Test DistilBERT Inference"
      ],
      "metadata": {
        "id": "8e75GKpUDge0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def classify_intent(input_text, model, tokenizer, intent_labels):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        predicted_class = torch.argmax(probs, dim=-1).item()\n",
        "        confidence = probs[0][predicted_class].item()\n",
        "    return intent_labels[predicted_class], confidence\n",
        "\n",
        "intent_labels = ['delivery_status', 'billing_issue', 'account_update', 'service_inquiry',\n",
        "                 'fuel_card_query', 'general_query', 'greeting', 'small_talk',\n",
        "                 'compliment', 'weather_query', 'direction', 'login_issue']\n",
        "test_inputs = [\"Hello!\", \"How’s the weather there?\", \"You’re awesome!\", \"Where is my shipment?\",\n",
        "               \"How do I get to Chicago?\", \"Address is not correct on card\",\n",
        "               \"My Comdata card is not working\", \"I am not able to login to the Driven website\",\n",
        "               \"I want to change my card pin on the Driven website\"]\n",
        "for input_text in test_inputs:\n",
        "    intent, confidence = classify_intent(input_text, distilbert_model, distilbert_tokenizer, intent_labels)\n",
        "    print(f\"Input: {input_text}\")\n",
        "    print(f\"DistilBERT Intent: {intent} (Confidence: {confidence:.2f})\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD--AJp9DSZY",
        "outputId": "47f5d277-7254-4cce-c3f0-061bb8bec6ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Hello!\n",
            "DistilBERT Intent: general_query (Confidence: 0.10)\n",
            "\n",
            "\n",
            "Input: How’s the weather there?\n",
            "DistilBERT Intent: general_query (Confidence: 0.10)\n",
            "\n",
            "\n",
            "Input: You’re awesome!\n",
            "DistilBERT Intent: greeting (Confidence: 0.11)\n",
            "\n",
            "\n",
            "Input: Where is my shipment?\n",
            "DistilBERT Intent: general_query (Confidence: 0.11)\n",
            "\n",
            "\n",
            "Input: How do I get to Chicago?\n",
            "DistilBERT Intent: general_query (Confidence: 0.10)\n",
            "\n",
            "\n",
            "Input: Address is not correct on card\n",
            "DistilBERT Intent: general_query (Confidence: 0.10)\n",
            "\n",
            "\n",
            "Input: My Comdata card is not working\n",
            "DistilBERT Intent: general_query (Confidence: 0.10)\n",
            "\n",
            "\n",
            "Input: I am not able to login to the Driven website\n",
            "DistilBERT Intent: general_query (Confidence: 0.10)\n",
            "\n",
            "\n",
            "Input: I want to change my card pin on the Driven website\n",
            "DistilBERT Intent: general_query (Confidence: 0.10)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuZdZFGynOlK"
      },
      "source": [
        "## Step 7: Evaluate Model\n",
        "\n",
        "Fix class mismatch by specifying labels in classification_report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSdwCtHcnOlK",
        "outputId": "35bd043c-9695-4078-c496-a197809e8dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot evaluate: Trainer or evaluation dataset is not available.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def evaluate_model(trainer, eval_dataset, label_map, unique_labels):\n",
        "    \"\"\"Evaluate the model on the evaluation dataset and compute metrics.\"\"\"\n",
        "    if trainer is None or eval_dataset is None:\n",
        "        print(\"Error: Trainer or evaluation dataset is not available.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        print(\"Evaluating model on evaluation dataset...\")\n",
        "        predictions = trainer.predict(eval_dataset)\n",
        "        logits = predictions.predictions\n",
        "        labels = predictions.label_ids\n",
        "        preds = logits.argmax(axis=-1)\n",
        "\n",
        "        # Validate labels\n",
        "        unique_label_ids = [label_map[label] for label in unique_labels]\n",
        "        invalid_labels = set(labels) - set(unique_label_ids)\n",
        "        invalid_preds = set(preds) - set(unique_label_ids)\n",
        "        if invalid_labels or invalid_preds:\n",
        "            print(f\"Warning: Invalid labels found in true labels: {invalid_labels}\")\n",
        "            print(f\"Warning: Invalid labels found in predictions: {invalid_preds}\")\n",
        "            valid_mask = np.isin(labels, unique_label_ids) & np.isin(preds, unique_label_ids)\n",
        "            labels = labels[valid_mask]\n",
        "            preds = preds[valid_mask]\n",
        "            if len(labels) == 0:\n",
        "                print(\"Error: No valid labels remain after filtering.\")\n",
        "                return None\n",
        "\n",
        "        # Log label distributions\n",
        "        true_label_counts = Counter(labels)\n",
        "        pred_label_counts = Counter(preds)\n",
        "        print(\"True label distribution:\", {unique_labels[id]: count for id, count in true_label_counts.items()})\n",
        "        print(\"Predicted label distribution:\", {unique_labels[id]: count for id, count in pred_label_counts.items()})\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(labels, preds, labels=unique_label_ids)\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(\n",
        "            cm,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap='Blues',\n",
        "            xticklabels=unique_labels,\n",
        "            yticklabels=unique_labels\n",
        "        )\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Compute metrics with zero_division\n",
        "        accuracy = accuracy_score(labels, preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            labels, preds, average='weighted', zero_division=0\n",
        "        )\n",
        "\n",
        "        # Generate classification report\n",
        "        label_names = [label for label in unique_labels]\n",
        "        try:\n",
        "            report = classification_report(\n",
        "                labels, preds, target_names=label_names, labels=unique_label_ids, zero_division=0\n",
        "            )\n",
        "        except ValueError as e:\n",
        "            print(f\"Error generating classification report: {e}\")\n",
        "            report = \"Classification report could not be generated.\"\n",
        "\n",
        "        results = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'classification_report': report\n",
        "            'confusion_matrix': cm.tolist()\n",
        "        }\n",
        "\n",
        "        print(f\"Evaluation Results:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-Score: {f1:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(report)\n",
        "\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error during evaluation: {e}\")\n",
        "        print(f\"True labels unique values: {np.unique(labels)}\")\n",
        "        print(f\"Predicted labels unique values: {np.unique(preds)}\")\n",
        "        print(f\"Expected label IDs: {[label_map[label] for label in unique_labels]}\")\n",
        "        return None\n",
        "\n",
        "# Run evaluation\n",
        "if distilbert_trainer is not None and eval_dataset is not None:\n",
        "    eval_results = evaluate_model(distilbert_trainer, eval_dataset, label_map, unique_labels)\n",
        "else:\n",
        "    print(\"Cannot evaluate: Trainer or evaluation dataset is not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load saved model and reconstruct arguments for evaluate_model."
      ],
      "metadata": {
        "id": "PZw9X_mdOEMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import random\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "def load_and_prepare_eval_arguments(model_path='./chatbot_model', dataset_file='trucking_chatbot_test_dataset.csv'):\n",
        "    \"\"\"Load saved model and reconstruct arguments for evaluate_model.\"\"\"\n",
        "    try:\n",
        "        # Load model and tokenizer\n",
        "        print(f\"Loading model and tokenizer from {model_path}\")\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path, clean_up_tokenization_spaces=True)\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "\n",
        "        # Load unique labels\n",
        "        labels_file = os.path.join(model_path, 'labels.json')\n",
        "        if not os.path.exists(labels_file):\n",
        "            print(f\"Labels file {labels_file} not found. Using default labels.\")\n",
        "            unique_labels = ['delivery_status', 'billing_issue', 'account_update', 'service_inquiry',\n",
        "                             'fuel_card_query', 'general_query', 'greeting', 'small_talk',\n",
        "                             'compliment', 'weather_query', 'direction', 'login_issue']\n",
        "        else:\n",
        "            with open(labels_file, 'r') as f:\n",
        "                unique_labels = json.load(f)\n",
        "\n",
        "        # Load or create label map\n",
        "        label_map_file = os.path.join(model_path, 'label_map.json')\n",
        "        if os.path.exists(label_map_file):\n",
        "            with open(label_map_file, 'r') as f:\n",
        "                label_map = json.load(f)\n",
        "        else:\n",
        "            print(f\"Label map file {label_map_file} not found. Creating from unique labels.\")\n",
        "            label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "            with open(label_map_file, 'w') as f:\n",
        "                json.dump(label_map, f)\n",
        "            print(f\"Saved label_map to {label_map_file}\")\n",
        "\n",
        "        # Load and prepare dataset\n",
        "        print(f\"Loading dataset from {dataset_file}\")\n",
        "        try:\n",
        "            df = pd.read_csv(dataset_file)\n",
        "        except FileNotFoundError:\n",
        "            print('Dataset not found. Using Twitter dataset.')\n",
        "            try:\n",
        "                df = pd.read_csv('tweets.csv')\n",
        "            except FileNotFoundError:\n",
        "                print('Using default dataset.')\n",
        "                data = {\n",
        "                    'text': [\n",
        "                        'Where is my shipment from Speedway?', 'Why is my Comdata bill so high?',\n",
        "                        'Need to update my address for IFTA', 'What are your hauling rates?',\n",
        "                        'Help with my account', 'Hello', 'How are you', 'How can I help you',\n",
        "                        'Track my cargo', 'Overcharged on Comdata invoice', 'Hi there',\n",
        "                        'Change my contact info', 'Tell me about Comdata services', 'Lost my shipment',\n",
        "                        'Good morning', 'Thanks for the help', 'Bye', 'What’s new?',\n",
        "                        'How’s it going?', 'How’s your day going?', 'Any big plans?',\n",
        "                        'How’s the trucking life?', 'You’re awesome!', 'Great job!',\n",
        "                        'How’s the weather there?', 'Is it raining?',\n",
        "                        'How do I get to Chicago?', 'What’s the best route to Miami?',\n",
        "                        'Directions to the nearest truck stop', 'Can you route me to Denver?',\n",
        "                        'Address is not correct on card', 'Update my billing address',\n",
        "                        'Wrong address on my account', 'Change address for fuel card',\n",
        "                        'My Comdata card is not working', 'Comdata card declined at pump',\n",
        "                        'Fix my Comdata card issue', 'Why isn’t my Comdata card accepted?',\n",
        "                        'I am not able to login to the Driven website', 'Can’t access my account on Driven',\n",
        "                        'Login error on the Driven website', 'Driven website login not working',\n",
        "                        'I want to change my card pin on the Driven website', 'Update my fuel card PIN on Driven',\n",
        "                        'Need to reset my card PIN for Driven', 'Change PIN for my Comdata card on Driven website'\n",
        "                    ],\n",
        "                    'intent': [\n",
        "                        'delivery_status', 'billing_issue', 'account_update', 'service_inquiry',\n",
        "                        'general_query', 'greeting', 'greeting', 'greeting', 'delivery_status',\n",
        "                        'billing_issue', 'greeting', 'account_update', 'fuel_card_query',\n",
        "                        'general_query', 'greeting', 'farewell', 'farewell', 'small_talk',\n",
        "                        'small_talk', 'small_talk', 'small_talk', 'small_talk', 'compliment',\n",
        "                        'compliment', 'weather_query', 'weather_query',\n",
        "                        'direction', 'direction', 'direction', 'direction',\n",
        "                        'account_update', 'account_update', 'account_update', 'account_update',\n",
        "                        'fuel_card_query', 'fuel_card_query', 'fuel_card_query', 'fuel_card_query',\n",
        "                        'login_issue', 'login_issue', 'login_issue', 'login_issue',\n",
        "                        'account_update', 'account_update', 'account_update', 'account_update'\n",
        "                    ]\n",
        "                }\n",
        "                df = pd.DataFrame(data)\n",
        "\n",
        "        # Validate intents\n",
        "        invalid_intents = set(df['intent']) - set(unique_labels)\n",
        "        if invalid_intents:\n",
        "            print(f\"Warning: Invalid intents in dataset: {invalid_intents}. Filtering them out.\")\n",
        "            df = df[df['intent'].isin(unique_labels)]\n",
        "\n",
        "        # Encode labels\n",
        "        le = LabelEncoder()\n",
        "        le.fit(unique_labels)\n",
        "        df['label'] = le.transform(df['intent'])\n",
        "\n",
        "        # Create evaluation dataset\n",
        "        dataset = Dataset.from_pandas(df[['text', 'label']])\n",
        "        indices = list(range(len(dataset)))\n",
        "        random.shuffle(indices)\n",
        "        split_idx = int(0.8 * len(indices))\n",
        "        eval_indices = indices[split_idx:]\n",
        "        eval_dataset = dataset.select(eval_indices)\n",
        "        print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "        # Verify labels\n",
        "        eval_labels = eval_dataset['label']\n",
        "        invalid_eval_labels = set(eval_labels) - set(range(len(unique_labels)))\n",
        "        if invalid_eval_labels:\n",
        "            print(f\"Error: Invalid label IDs in eval_dataset: {invalid_eval_labels}\")\n",
        "            return None, None, None, None\n",
        "\n",
        "        # Tokenize dataset\n",
        "        def tokenize_function(example):\n",
        "            try:\n",
        "                tokenized = tokenizer(\n",
        "                    example['text'],\n",
        "                    padding='max_length',\n",
        "                    truncation=True,\n",
        "                    max_length=128,\n",
        "                    return_tensors='pt',\n",
        "                    clean_up_tokenization_spaces=True\n",
        "                )\n",
        "                return {\n",
        "                    'input_ids': tokenized['input_ids'].squeeze(0),\n",
        "                    'attention_mask': tokenized['attention_mask'].squeeze(0),\n",
        "                    'labels': torch.tensor(example['label'], dtype=torch.long).to(device)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f'Error in tokenize_function: {e}')\n",
        "                raise\n",
        "\n",
        "        print(\"Tokenizing evaluation dataset...\")\n",
        "        tokenized_eval_dataset = eval_dataset.map(\n",
        "            tokenize_function,\n",
        "            remove_columns=['text', 'label'],\n",
        "            desc=\"Tokenizing eval dataset\"\n",
        "        )\n",
        "        tokenized_eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "        print(\"Tokenization complete.\")\n",
        "\n",
        "        # Create trainer\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='./distilbert_results',\n",
        "            per_device_eval_batch_size=4,\n",
        "            eval_strategy='epoch',\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            dataloader_num_workers=0\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            eval_dataset=tokenized_eval_dataset,\n",
        "            compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        print(\"Successfully reconstructed trainer, eval_dataset, label_map, and unique_labels.\")\n",
        "        return trainer, tokenized_eval_dataset, label_map, unique_labels\n",
        "    except Exception as e:\n",
        "        print(f\"Error reconstructing evaluation arguments: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# Reconstruct arguments and evaluate\n",
        "trainer, eval_dataset, label_map, unique_labels = load_and_prepare_eval_arguments()\n",
        "if trainer is not None and eval_dataset is not None:\n",
        "    eval_results = evaluate_model(trainer, eval_dataset, label_map, unique_labels)\n",
        "else:\n",
        "    print(\"Failed to reconstruct arguments for evaluation.\")"
      ],
      "metadata": {
        "id": "hykwUew5OBma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBeDZkVynOlL"
      },
      "source": [
        "## Step 8: Dialogue Management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "SUU9SfEDnOlL"
      },
      "outputs": [],
      "source": [
        "from pickle import NONE\n",
        "class DialogueManager:\n",
        "    def __init__(self, model, tokenizer, label_map, dialoggpt_model, dialoggpt_tokenizer):\n",
        "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "      self.model = model\n",
        "      self.model.to(device)\n",
        "      model.eval()\n",
        "      #print(f\"Model is on device: {next(model.parameters()).device}\")\n",
        "      self.tokenizer = tokenizer\n",
        "      self.dialoggpt_model = dialoggpt_model\n",
        "      self.dialoggpt_model.to(device)\n",
        "      self.dialoggpt_tokenizer = dialoggpt_tokenizer\n",
        "      self.reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "      self.state = 'INITIAL'\n",
        "      self.context = defaultdict(str)\n",
        "      self.history = []\n",
        "      self.fallback_responses = {\n",
        "          'greeting': {\n",
        "              'INITIAL': [\n",
        "                  'Hello! How can I assist you with your trucking needs today?',\n",
        "                  'Hi there! What can I help you with regarding your shipments or account?'\n",
        "              ],\n",
        "              'POST_GREETING': [\n",
        "                  'Thanks for the greeting! How can I assist with your shipment or billing needs?',\n",
        "                  'Nice to connect again! What’s on your mind today?'\n",
        "              ]\n",
        "          },\n",
        "          'farewell': {\n",
        "              'INITIAL': [\n",
        "                  'Goodbye! Feel free to reach out if you need further assistance.',\n",
        "                  'Thanks for connecting! Let me know if you have more questions later.'\n",
        "              ]\n",
        "          },\n",
        "          'small_talk': {\n",
        "              'INITIAL': {\n",
        "                  'mood': ['My day’s going smoothly, thanks for asking! How’s yours?'],\n",
        "                  'plans': ['No big plans here, just helping truckers! Got any big plans yourself?'],\n",
        "                  'industry': ['Trucking life’s always moving! How’s it treating you these days?'],\n",
        "                  'default': ['All’s well here, thanks for asking! Need help with your shipments?']\n",
        "              }\n",
        "          },\n",
        "          'compliment': {\n",
        "              'INITIAL': ['Thank you, that’s kind of you! How can I assist you today?']\n",
        "          },\n",
        "          'weather_query': {\n",
        "              'INITIAL': ['Weather’s clear here, but I can check for your route! Where are you headed?']\n",
        "          }\n",
        "      }\n",
        "      self.trucking_responses = {\n",
        "          'delivery_status': {\n",
        "              'INITIAL': 'I can check your shipment status for {location}. Please provide the shipment ID.',\n",
        "              'AWAITING_SHIPMENT_ID': 'Could you share the shipment ID to proceed with tracking?',\n",
        "              'PROVIDED_SHIPMENT_ID': 'Thank you. Shipment {shipment_id} is currently at {location}. Would you like the estimated arrival time?'\n",
        "          },\n",
        "          'billing_issue': {\n",
        "              'INITIAL': 'Let’s review your billing issue with {company}. Is this about an overcharge or a payment concern?',\n",
        "              'AWAITING_DETAILS': 'Can you provide the invoice number or {company} transaction amount?',\n",
        "              'RESOLVING': 'I’ve noted a {amount} charge on your {company} invoice. Would you like to dispute this?'\n",
        "          },\n",
        "          'account_update': {\n",
        "              'INITIAL': 'I can help update your account details for {regulation}. What information would you like to change?',\n",
        "              'AWAITING_INFO': 'Please provide the new address or contact details for {regulation}.',\n",
        "              'CONFIRMING': 'I have {new_info} for your {regulation} update. Please confirm to proceed.'\n",
        "          },\n",
        "          'service_inquiry': {\n",
        "              'INITIAL': 'I can provide information on our services. Are you interested in flatbed, refrigerated, or bulk transport rates?',\n",
        "              'AWAITING_SPECIFICS': 'Which service are you inquiring about: flatbed, refrigerated, or bulk transport?'\n",
        "          },\n",
        "          'fuel_card_query': {\n",
        "              'INITIAL': 'I can assist with your {company} fuel card or {regulation} query. Is this about a balance, transaction, or compliance?',\n",
        "              'AWAITING_DETAILS': 'Could you specify if this is a {company} card issue or a {regulation} tax question?'\n",
        "          },\n",
        "          'general_query': {\n",
        "              'INITIAL': 'Could you clarify your request? I can help with delivery, billing, account updates, or {company}/{regulation} services.'\n",
        "          }\n",
        "      }\n",
        "\n",
        "    def predict_intent(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        input_ids = inputs['input_ids'].to(device)\n",
        "        attention_mask = inputs['attention_mask'].to(device)\n",
        "        #print(f\"predict_intent input_ids device: {input_ids.device}\")\n",
        "        #print(f\"predict_intent attention_mask device: {attention_mask.device}\")\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            predicted_class = torch.argmax(probs, dim=-1).to(device)  # Ensure device consistency\n",
        "            predicted_class = predicted_class.item()  # Convert to scalar\n",
        "            confidence = probs[0][predicted_class].item()\n",
        "            # Log top 3 intents for debugging\n",
        "            top_probs, top_indices = torch.topk(probs[0], 3)\n",
        "            top_intents = [(unique_labels[idx.item()], prob.item()) for idx, prob in zip(top_indices, top_probs)]\n",
        "            print(f\"Top 3 intents: {top_intents}\")\n",
        "        return self.reverse_label_map.get(predicted_class, 'general_query')  # Fallback to general_query\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        entities = []\n",
        "        text = text.lower()\n",
        "        if 'speedway' in text:\n",
        "            entities.append({'entity': 'location', 'value': 'Speedway'})\n",
        "        if 'comdata' in text:\n",
        "            entities.append({'entity': 'company', 'value': 'Comdata'})\n",
        "        if 'ifta' in text:\n",
        "            entities.append({'entity': 'regulation', 'value': 'IFTA'})\n",
        "        shipment_match = re.search(r'\\bship\\d+\\b', text, re.IGNORECASE)\n",
        "        if shipment_match:\n",
        "            entities.append({'entity': 'shipment_id', 'value': shipment_match.group()})\n",
        "        amount_match = re.search(r'\\$\\d+', text)\n",
        "        if amount_match:\n",
        "            entities.append({'entity': 'amount', 'value': amount_match.group()})\n",
        "        direction_match = re.search(r'\\bgo\\d+\\b | \\bturn\\d+\\b | \\bdirection\\d+\\b', text, re.IGNORECASE)\n",
        "        if direction_match:\n",
        "            entities.append({'entity': 'direction', 'value': direction_match.group()})\n",
        "        if 'new address' in text or 'change to' in text:\n",
        "            new_info = text.split('new address')[-1].strip() or text.split('change to')[-1].strip()\n",
        "            entities.append({'entity': 'new_info', 'value': new_info[:50]})\n",
        "        if 'driven' in text:\n",
        "                entities.append({'entity': 'website', 'value': 'Driven'})\n",
        "        if 'pin' in text:\n",
        "                entities.append({'entity': 'pin', 'value': 'pin'})\n",
        "        if 'login' in text or 'website' in text:\n",
        "                entities.append({'entity': 'login', 'value': 'login'})\n",
        "        return entities\n",
        "\n",
        "    def get_dialoggpt_response(self, text):\n",
        "        try:\n",
        "            if self.dialoggpt_tokenizer.pad_token is None:\n",
        "                self.dialoggpt_tokenizer.pad_token = self.dialoggpt_tokenizer.eos_token\n",
        "            input_ids = self.dialoggpt_tokenizer.encode(text + self.dialoggpt_tokenizer.eos_token, return_tensors='pt')\n",
        "            input_ids = input_ids.to(device)\n",
        "            #print(f\"get_dialoggpt_response: input_ids device: {input_ids.device}\")\n",
        "            reply_ids = self.dialoggpt_model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=128,\n",
        "                pad_token_id=self.dialoggpt_tokenizer.eos_token_id,\n",
        "                no_repeat_ngram_size=3,\n",
        "                top_p=0.9,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            #print(f\"get_dialoggpt_response: reply_ids device: {reply_ids.device}\")\n",
        "            response = self.dialoggpt_tokenizer.decode(reply_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "            #print(f\"get_dialoggpt_response: response device: {response.device}\")\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f'Error getting DialogGPT response: {e}')\n",
        "            return None\n",
        "\n",
        "    def update_context(self, intent, entities, text):\n",
        "        self.history.append((intent, text, ''))\n",
        "        for entity in entities:\n",
        "            self.context[entity['entity']] = entity['value']\n",
        "        if intent == 'greeting':\n",
        "            self.context['greeted'] = 'true'\n",
        "        if intent == 'small_talk':\n",
        "            text = text.lower()\n",
        "            if 'day' in text or 'how’s your day' in text:\n",
        "                self.context['small_talk_type'] = 'mood'\n",
        "            elif 'plans' in text or 'big plans' in text:\n",
        "                self.context['small_talk_type'] = 'plans'\n",
        "            elif 'trucking' in text or 'truck' in text:\n",
        "                self.context['small_talk_type'] = 'industry'\n",
        "            else:\n",
        "                self.context['small_talk_type'] = 'default'\n",
        "\n",
        "    def transition_state(self, intent, entities, text):\n",
        "        if intent in ['greeting', 'small_talk', 'compliment', 'weather_query']:\n",
        "            self.state = 'POST_GREETING' if self.state == 'INITIAL' and intent == 'greeting' else self.state\n",
        "        elif intent == 'farewell':\n",
        "            self.state = 'INITIAL'\n",
        "        elif intent == 'delivery_status':\n",
        "            if self.state == 'INITIAL' and 'shipment_id' not in self.context:\n",
        "                self.state = 'AWAITING_SHIPMENT_ID'\n",
        "            elif 'shipment_id' in self.context:\n",
        "                self.state = 'PROVIDED_SHIPMENT_ID'\n",
        "        elif intent == 'billing_issue':\n",
        "            if self.state == 'INITIAL' and not any(e['entity'] in ['amount', 'transaction_id'] for e in entities):\n",
        "                self.state = 'AWAITING_DETAILS'\n",
        "            elif any(e['entity'] in ['amount', 'transaction_id'] for e in entities):\n",
        "                self.state = 'RESOLVING'\n",
        "        elif intent == 'account_update':\n",
        "            if self.state == 'INITIAL' and 'new_info' not in self.context:\n",
        "                self.state = 'AWAITING_INFO'\n",
        "            elif 'new_info' in self.context:\n",
        "                self.state = 'CONFIRMING'\n",
        "        elif intent == 'service_inquiry':\n",
        "            if self.state == 'INITIAL' and 'service_type' not in self.context:\n",
        "                self.state = 'AWAITING_SPECIFICS'\n",
        "        elif intent == 'fuel_card_query':\n",
        "            if self.state == 'INITIAL' and not any(e['entity'] in ['balance', 'transaction'] for e in entities):\n",
        "                self.state = 'AWAITING_DETAILS'\n",
        "\n",
        "    def generate_response(self, intent, entities, text):\n",
        "        self.update_context(intent, entities, text)\n",
        "        self.transition_state(intent, entities, text)\n",
        "\n",
        "        if intent in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']:\n",
        "            dialog_response = self.get_dialoggpt_response(text)\n",
        "            if not dialog_response or len(dialog_response) < 5 or any(word in dialog_response.lower() for word in ['inappropriate', 'sorry', 'weird', 'lol']):\n",
        "                small_talk_type = self.context.get('small_talk_type', 'default')\n",
        "                if intent == 'small_talk':\n",
        "                    response_options = self.fallback_responses[intent]['INITIAL'].get(small_talk_type, self.fallback_responses[intent]['INITIAL']['default'])\n",
        "                else:\n",
        "                    response_options = self.fallback_responses.get(intent, {'INITIAL': ['Could you clarify your request?']}).get(self.state, self.fallback_responses[intent]['INITIAL'])\n",
        "                response = random.choice(response_options) if isinstance(response_options, list) else response_options\n",
        "            else:\n",
        "                response = dialog_response + ' Need assistance with your trucking needs?'\n",
        "            if intent == 'greeting' and 'good morning' in text.lower() and datetime.now().hour < 12:\n",
        "                response = random.choice(['Good morning to you too! How can I assist today?', 'Morning! Ready to help with your trucking needs.'])\n",
        "        else:\n",
        "            response_template = self.trucking_responses.get(intent, self.trucking_responses['general_query']).get(self.state, self.trucking_responses[intent]['INITIAL'])\n",
        "            try:\n",
        "                response = response_template.format(\n",
        "                    location=self.context.get('location', 'unknown'),\n",
        "                    company=self.context.get('company', 'unknown'),\n",
        "                    regulation=self.context.get('regulation', 'unknown'),\n",
        "                    shipment_id=self.context.get('shipment_id', 'unknown'),\n",
        "                    amount=self.context.get('amount', 'unknown'),\n",
        "                    new_info=self.context.get('new_info', 'unknown')\n",
        "                )\n",
        "            except KeyError:\n",
        "                response = response_template\n",
        "\n",
        "        if self.context.get('greeted') == 'true' and intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'] and 'PROVIDED' in self.state:\n",
        "            response = f'Since you greeted me earlier, I’m ready to assist! {response}'\n",
        "\n",
        "        self.history[-1] = (intent, text, response)\n",
        "        resolved = self.state in ['PROVIDED_SHIPMENT_ID', 'RESOLVING', 'CONFIRMING'] and intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query']\n",
        "        return response, resolved\n",
        "\n",
        "    def evaluate_dialogue_success(self):\n",
        "        resolved = sum(1 for intent, _, _ in self.history if intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'] and self.state in ['PROVIDED_SHIPMENT_ID', 'RESOLVING', 'CONFIRMING'])\n",
        "        total = sum(1 for intent, _, _ in self.history if intent not in ['greeting', 'farewell', 'small_talk', 'compliment', 'weather_query'])\n",
        "        return resolved / total if total > 0 else 0.0\n",
        "\n",
        "try:\n",
        "  if label_map is NONE:\n",
        "    with open('label_map.json', 'r') as f:\n",
        "        label_map = json.load(f)\n",
        "  else:\n",
        "    dialogue_manager = DialogueManager(distilbert_model, tokenizer, label_map, dialoggpt_model, dialoggpt_tokenizer)\n",
        "except FileNotFoundError:\n",
        "    print('Error: label_map.json not found. Please ensure Cell 6 has run successfully.')\n",
        "    dialogue_manager = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWPficYenOlL"
      },
      "source": [
        "## Step 9: Interactive Chatbot UI\n",
        "\n",
        "UI with DialogGPT conversational support trained on Twitter data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "6bad5e1eb3074830bb9d60e2c34e94df",
            "ad6e1929b67445e3bcccd739ed4de2f9",
            "05744628267b49a08fdd80bd101fb84d",
            "743074dd4b324bd59ef72c5f70fae8a2",
            "170d4d9ee90f4197aa6c0c933c5098de",
            "a190939a5db643d5a7ca246eaa98b7a7",
            "1317741d298a4e31b9bbbdf0f30243d5",
            "5d44e00f0c164f13b1686369a257e067",
            "7c83092f567b41ff83b2a96195fb7cfa",
            "cc85320d1e9a477db3f70d3823117baa",
            "f914762ca68b4ddbbe973738b3fa9105",
            "4f5bb5cf62924563b4034b5be70412ef",
            "efb91bb1e5da4142a3a1c53a23f9b8d9",
            "f3ffc30bdf7f4f04a409a0ee43f36e42",
            "bdac38d5570c4d84ac6ff2beaca09ecf",
            "6dff2059fb4d4efdbb62742b74cecb6c",
            "03dbd39ec03b48259436e10a7d26b311",
            "b1aef835bd9b4b1d822c23be3ea6d269",
            "042db2a8c1c743e0b05f20eee8b37760"
          ]
        },
        "id": "jdzB_dOMnOlL",
        "outputId": "0bf84817-2466-4209-db68-8b757d7f9ce1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h3>Trucking Co. Customer Chatbot</h3>'), Text(value='', description='Query:', layo…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bad5e1eb3074830bb9d60e2c34e94df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! You can greet me, chat about your day, or ask about delivery, billing, or Comdata/IFTA services.\n",
            "Type your query and click Submit.\n"
          ]
        }
      ],
      "source": [
        "if dialogue_manager is None:\n",
        "    print('Dialogue manager not initialized. Please fix previous errors.')\n",
        "else:\n",
        "    # Create UI\n",
        "    input_box = widgets.Text(\n",
        "        value='',\n",
        "        placeholder='Type your query (e.g., Hello, How’s your day?, or Where’s my shipment?)',\n",
        "        description='Query:',\n",
        "        layout={'width': '500px'}\n",
        "    )\n",
        "    submit_button = widgets.Button(\n",
        "        description='Submit',\n",
        "        button_style='success',\n",
        "        tooltip='Submit query'\n",
        "    )\n",
        "    follow_up_button1 = widgets.Button(\n",
        "        description='Request ETA',\n",
        "        button_style='info',\n",
        "        tooltip='Request ETA',\n",
        "        layout={'visibility': 'hidden'}\n",
        "    )\n",
        "    follow_up_button2 = widgets.Button(\n",
        "        description='Confirm',\n",
        "        button_style='success',\n",
        "        tooltip='Confirm action',\n",
        "        layout={'visibility': 'hidden'}\n",
        "    )\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    def on_submit_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            user_input = input_box.value.strip()\n",
        "            if not user_input:\n",
        "                print('Please enter a query.')\n",
        "                return\n",
        "            print(f'You: {user_input}')\n",
        "            try:\n",
        "                intent = dialogue_manager.predict_intent(user_input)\n",
        "                entities = dialogue_manager.extract_entities(user_input)\n",
        "                response, resolved = dialogue_manager.generate_response(intent, entities, user_input)\n",
        "                print(f'Bot: {response}')\n",
        "                input_box.value = ''\n",
        "                follow_up_button1.layout.visibility = 'visible' if dialogue_manager.state == 'PROVIDED_SHIPMENT_ID' else 'hidden'\n",
        "                follow_up_button2.layout.visibility = 'visible' if dialogue_manager.state in ['RESOLVING', 'CONFIRMING'] else 'hidden'\n",
        "                success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "                if success_rate > 0:\n",
        "                    print(f'Dialogue Success Rate: {success_rate:.2f}')\n",
        "            except Exception as e:\n",
        "                print(f'Error processing query: {e}')\n",
        "\n",
        "    def on_follow_up1_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            response = f'The estimated arrival time for shipment {dialogue_manager.context.get(\"shipment_id\", \"unknown\")} is tomorrow by 3 PM.'\n",
        "            dialogue_manager.history.append(('follow_up', 'Request ETA', response))\n",
        "            print(f'Bot: {response}')\n",
        "            follow_up_button1.layout.visibility = 'hidden'\n",
        "            success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "            if success_rate > 0:\n",
        "                print(f'Dialogue Success Rate: {success_rate:.2f}')\n",
        "\n",
        "    def on_follow_up2_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            if dialogue_manager.state == 'CONFIRMING':\n",
        "                response = f'Confirmed. {dialogue_manager.context.get(\"new_info\", \"action\")} has been updated.'\n",
        "            else:\n",
        "                response = f'Dispute for {dialogue_manager.context.get(\"amount\", \"unknown\")} has been submitted.'\n",
        "            dialogue_manager.history.append(('follow_up', 'Confirm', response))\n",
        "            dialogue_manager.state = 'INITIAL'\n",
        "            print(f'Bot: {response}')\n",
        "            follow_up_button2.layout.visibility = 'hidden'\n",
        "            success_rate = dialogue_manager.evaluate_dialogue_success()\n",
        "            if success_rate > 0:\n",
        "                print(f'Dialogue Success Rate: {success_rate:.2f}')\n",
        "\n",
        "    submit_button.on_click(on_submit_clicked)\n",
        "    follow_up_button1.on_click(on_follow_up1_clicked)\n",
        "    follow_up_button2.on_click(on_follow_up2_clicked)\n",
        "\n",
        "    # Display UI\n",
        "    display(widgets.VBox([\n",
        "        widgets.HTML('<h3>Trucking Co. Customer Chatbot</h3>'),\n",
        "        input_box,\n",
        "        submit_button,\n",
        "        follow_up_button1,\n",
        "        follow_up_button2,\n",
        "        output_area\n",
        "    ]))\n",
        "    print('Welcome! You can greet me, chat about your day, or ask about delivery, billing, or Comdata/IFTA services.')\n",
        "    print('Type your query and click Submit.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8",
      "language": "python",
      "name": "python3.8"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efdeacd788d348df8f477c6e49e9ce00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_890bf3fa631347c584d0f1d3c7a60b8b",
              "IPY_MODEL_aff828c8ece74276a45cbe5e64bbfc92",
              "IPY_MODEL_dea6f8befabb40ea80cb3eda8a47dba7"
            ],
            "layout": "IPY_MODEL_fb0591b5d5d54cf4bed48aa2fa6192c8",
            "tabbable": null,
            "tooltip": null
          }
        },
        "890bf3fa631347c584d0f1d3c7a60b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b19ec1d0f0ae4b34ac2b453ca92e3477",
            "placeholder": "​",
            "style": "IPY_MODEL_cc9de17df52c4a91ba51fbf9d5de5637",
            "tabbable": null,
            "tooltip": null,
            "value": ""
          }
        },
        "aff828c8ece74276a45cbe5e64bbfc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_389823c327094fa0a6c1b44eedd350a4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b86d2921422d45ca8279b12acbefcc52",
            "tabbable": null,
            "tooltip": null,
            "value": 0
          }
        },
        "dea6f8befabb40ea80cb3eda8a47dba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_0efe30fe7ffa4591986810539ffa9d47",
            "placeholder": "​",
            "style": "IPY_MODEL_f90bba83ad144a5183b5ef9af1792874",
            "tabbable": null,
            "tooltip": null,
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "fb0591b5d5d54cf4bed48aa2fa6192c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b19ec1d0f0ae4b34ac2b453ca92e3477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9de17df52c4a91ba51fbf9d5de5637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "389823c327094fa0a6c1b44eedd350a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b86d2921422d45ca8279b12acbefcc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0efe30fe7ffa4591986810539ffa9d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90bba83ad144a5183b5ef9af1792874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "3bc6238ff5644a68b2c99a6d13b2f83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78bcd896921f4dbda67fdbb2f3fd481a",
              "IPY_MODEL_6b0edbee0350464bbe7d49829f06dadb",
              "IPY_MODEL_d1451290fe2e40b483e6517a6fe98e1a"
            ],
            "layout": "IPY_MODEL_4baf2ad3775d47f49e5edd7fc309d3ac",
            "tabbable": null,
            "tooltip": null
          }
        },
        "78bcd896921f4dbda67fdbb2f3fd481a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f7bbc76b03a24a688d1e31fb9686234a",
            "placeholder": "​",
            "style": "IPY_MODEL_057b930029564e73bb3a7a20733192cc",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "6b0edbee0350464bbe7d49829f06dadb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e57a08b704464f1cafc2b9d2d3b825da",
            "max": 1708677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5db0c26c3fbf46fe990b59ddff41dc95",
            "tabbable": null,
            "tooltip": null,
            "value": 1708677
          }
        },
        "d1451290fe2e40b483e6517a6fe98e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_0e90f41d09be48b9a99a10293f3ed95a",
            "placeholder": "​",
            "style": "IPY_MODEL_da47c2c60b76463bb4fd768c174d37ea",
            "tabbable": null,
            "tooltip": null,
            "value": " 1708677/1708677 [12:27&lt;00:00, 1940.26 examples/s]"
          }
        },
        "4baf2ad3775d47f49e5edd7fc309d3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7bbc76b03a24a688d1e31fb9686234a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057b930029564e73bb3a7a20733192cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e57a08b704464f1cafc2b9d2d3b825da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5db0c26c3fbf46fe990b59ddff41dc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e90f41d09be48b9a99a10293f3ed95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da47c2c60b76463bb4fd768c174d37ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "7d2ee64fbb654e9e9aaae77a9add2444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4f549c1af174ef3954314a2153cfa01",
              "IPY_MODEL_024aba354d904ef4b0ff565aba89ae8e",
              "IPY_MODEL_ed49733ab230441fa3c938d6866d5959"
            ],
            "layout": "IPY_MODEL_e1e243b1604f431f8a90244a538e3575",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f4f549c1af174ef3954314a2153cfa01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_88a388a014dc46af967ea38c1d3f0aef",
            "placeholder": "​",
            "style": "IPY_MODEL_9d4d3c3c66da48b08bde87d61d7f7dc0",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "024aba354d904ef4b0ff565aba89ae8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ae5e7a08e7d644c9a7d20a16b40ad2a8",
            "max": 1708677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07494715f43e499b8e13ad733a4ff010",
            "tabbable": null,
            "tooltip": null,
            "value": 1708677
          }
        },
        "ed49733ab230441fa3c938d6866d5959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_42fc1ad419b04b8a9bd465f52c41288a",
            "placeholder": "​",
            "style": "IPY_MODEL_13b9955d8f9e4be49626addaaaeae1e5",
            "tabbable": null,
            "tooltip": null,
            "value": " 1708677/1708677 [01:48&lt;00:00, 10412.71 examples/s]"
          }
        },
        "e1e243b1604f431f8a90244a538e3575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a388a014dc46af967ea38c1d3f0aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4d3c3c66da48b08bde87d61d7f7dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ae5e7a08e7d644c9a7d20a16b40ad2a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07494715f43e499b8e13ad733a4ff010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42fc1ad419b04b8a9bd465f52c41288a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b9955d8f9e4be49626addaaaeae1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "72e4efaec021457db95edbd28ba04aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92baa557a15347409a517868bbf14ba8",
              "IPY_MODEL_32e37f49da754972a06dd3e2bed47198",
              "IPY_MODEL_246775e809a342a19fb307fa0fc1ba11"
            ],
            "layout": "IPY_MODEL_75cf6144bbc041a3a3c675838eaaa00e",
            "tabbable": null,
            "tooltip": null
          }
        },
        "92baa557a15347409a517868bbf14ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f38847f9cbf64b3d99f485c634e91a25",
            "placeholder": "​",
            "style": "IPY_MODEL_3ad526c6fb3a410cae3f3e8a124eefba",
            "tabbable": null,
            "tooltip": null,
            "value": "Casting the dataset: 100%"
          }
        },
        "32e37f49da754972a06dd3e2bed47198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_154a58d0802844b5beebd01ee18c3019",
            "max": 1708677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bce89bcc0688410aacb0b46f33082fa6",
            "tabbable": null,
            "tooltip": null,
            "value": 1708677
          }
        },
        "246775e809a342a19fb307fa0fc1ba11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4727cb7891a247f79a13bb83109bee15",
            "placeholder": "​",
            "style": "IPY_MODEL_7ce6075dbc92445784850d8be543fbee",
            "tabbable": null,
            "tooltip": null,
            "value": " 1708677/1708677 [00:02&lt;00:00, 543878.32 examples/s]"
          }
        },
        "75cf6144bbc041a3a3c675838eaaa00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38847f9cbf64b3d99f485c634e91a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad526c6fb3a410cae3f3e8a124eefba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "154a58d0802844b5beebd01ee18c3019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce89bcc0688410aacb0b46f33082fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4727cb7891a247f79a13bb83109bee15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce6075dbc92445784850d8be543fbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "9318e8820e4b4e2c8ea7202b179ceeb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_999196219815413685763472e6142ad5",
              "IPY_MODEL_64e2ea72504e42829c6697e51ff5eae0",
              "IPY_MODEL_baa3aed738384c67bf2dbde204c6f26e"
            ],
            "layout": "IPY_MODEL_06f97a5ad0784795acc858a351b435b9",
            "tabbable": null,
            "tooltip": null
          }
        },
        "999196219815413685763472e6142ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5a82bf9ae2ba4335bdba96575214a9ae",
            "placeholder": "​",
            "style": "IPY_MODEL_fd1baa05fef24febb784339a6edc16e6",
            "tabbable": null,
            "tooltip": null,
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "64e2ea72504e42829c6697e51ff5eae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8f4abb7efef0425d96e44e818f36fea9",
            "max": 1366941,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f375c5a4a2f4ecea463b06ce4822189",
            "tabbable": null,
            "tooltip": null,
            "value": 1366941
          }
        },
        "baa3aed738384c67bf2dbde204c6f26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5cf78895ad3d4d868563becb609d5ece",
            "placeholder": "​",
            "style": "IPY_MODEL_672406c9723c4ac0814b1571118b970b",
            "tabbable": null,
            "tooltip": null,
            "value": " 1366941/1366941 [15:01&lt;00:00, 1659.83 examples/s]"
          }
        },
        "06f97a5ad0784795acc858a351b435b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a82bf9ae2ba4335bdba96575214a9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd1baa05fef24febb784339a6edc16e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8f4abb7efef0425d96e44e818f36fea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f375c5a4a2f4ecea463b06ce4822189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cf78895ad3d4d868563becb609d5ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672406c9723c4ac0814b1571118b970b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8c7939a5ce554852937ae41ba17d3fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82f3f63797de42438059a5ea28850dfe",
              "IPY_MODEL_eb3e5ca263884f8e87d8139250f80193",
              "IPY_MODEL_d4c07da591bc4dadb8eb384880dffd8d"
            ],
            "layout": "IPY_MODEL_182a6ee8f1ad4ab4abb37eb5adff5a8c",
            "tabbable": null,
            "tooltip": null
          }
        },
        "82f3f63797de42438059a5ea28850dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bbc6f67f0a5245c3976247d57f72bfd2",
            "placeholder": "​",
            "style": "IPY_MODEL_728dd2107c4b46899d57701822c6b05c",
            "tabbable": null,
            "tooltip": null,
            "value": "Tokenizing eval dataset: 100%"
          }
        },
        "eb3e5ca263884f8e87d8139250f80193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2b7247948e504b6b88a0c98b55e1297b",
            "max": 341736,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5080e5222a9c40c28b9b78a7196d7c83",
            "tabbable": null,
            "tooltip": null,
            "value": 341736
          }
        },
        "d4c07da591bc4dadb8eb384880dffd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fd8e0585d537436a88183932a289c986",
            "placeholder": "​",
            "style": "IPY_MODEL_f20298ab858b4ccab927b6c093555add",
            "tabbable": null,
            "tooltip": null,
            "value": " 341736/341736 [03:41&lt;00:00, 1644.16 examples/s]"
          }
        },
        "182a6ee8f1ad4ab4abb37eb5adff5a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbc6f67f0a5245c3976247d57f72bfd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728dd2107c4b46899d57701822c6b05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2b7247948e504b6b88a0c98b55e1297b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5080e5222a9c40c28b9b78a7196d7c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd8e0585d537436a88183932a289c986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20298ab858b4ccab927b6c093555add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "6bad5e1eb3074830bb9d60e2c34e94df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad6e1929b67445e3bcccd739ed4de2f9",
              "IPY_MODEL_05744628267b49a08fdd80bd101fb84d",
              "IPY_MODEL_743074dd4b324bd59ef72c5f70fae8a2",
              "IPY_MODEL_170d4d9ee90f4197aa6c0c933c5098de",
              "IPY_MODEL_a190939a5db643d5a7ca246eaa98b7a7",
              "IPY_MODEL_1317741d298a4e31b9bbbdf0f30243d5"
            ],
            "layout": "IPY_MODEL_5d44e00f0c164f13b1686369a257e067"
          }
        },
        "ad6e1929b67445e3bcccd739ed4de2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c83092f567b41ff83b2a96195fb7cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_cc85320d1e9a477db3f70d3823117baa",
            "value": "<h3>Trucking Co. Customer Chatbot</h3>"
          }
        },
        "05744628267b49a08fdd80bd101fb84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Query:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f914762ca68b4ddbbe973738b3fa9105",
            "placeholder": "Type your query (e.g., Hello, How’s your day?, or Where’s my shipment?)",
            "style": "IPY_MODEL_4f5bb5cf62924563b4034b5be70412ef",
            "value": ""
          }
        },
        "743074dd4b324bd59ef72c5f70fae8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_efb91bb1e5da4142a3a1c53a23f9b8d9",
            "style": "IPY_MODEL_f3ffc30bdf7f4f04a409a0ee43f36e42",
            "tooltip": "Submit query"
          }
        },
        "170d4d9ee90f4197aa6c0c933c5098de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Request ETA",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bdac38d5570c4d84ac6ff2beaca09ecf",
            "style": "IPY_MODEL_6dff2059fb4d4efdbb62742b74cecb6c",
            "tooltip": "Request ETA"
          }
        },
        "a190939a5db643d5a7ca246eaa98b7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Confirm",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_03dbd39ec03b48259436e10a7d26b311",
            "style": "IPY_MODEL_b1aef835bd9b4b1d822c23be3ea6d269",
            "tooltip": "Confirm action"
          }
        },
        "1317741d298a4e31b9bbbdf0f30243d5": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_042db2a8c1c743e0b05f20eee8b37760",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "You: Not able to login to Driven application\n",
                  "Bot: Could you specify if this is a Comdata card issue or a unknown tax question?\n"
                ]
              }
            ]
          }
        },
        "5d44e00f0c164f13b1686369a257e067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c83092f567b41ff83b2a96195fb7cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc85320d1e9a477db3f70d3823117baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f914762ca68b4ddbbe973738b3fa9105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "500px"
          }
        },
        "4f5bb5cf62924563b4034b5be70412ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb91bb1e5da4142a3a1c53a23f9b8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ffc30bdf7f4f04a409a0ee43f36e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "bdac38d5570c4d84ac6ff2beaca09ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6dff2059fb4d4efdbb62742b74cecb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "03dbd39ec03b48259436e10a7d26b311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b1aef835bd9b4b1d822c23be3ea6d269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "042db2a8c1c743e0b05f20eee8b37760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}